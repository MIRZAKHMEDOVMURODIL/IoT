{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495ee047-a33d-4b19-8035-7ea9ee4a5da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database\n",
      "Latest CSV file: C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231022.csv\n",
      "Row 1 merged successfully\n",
      "Row 2 merged successfully\n",
      "Row 3 merged successfully\n",
      "Row 4 merged successfully\n",
      "Row 5 merged successfully\n",
      "Row 6 merged successfully\n",
      "Row 7 merged successfully\n",
      "Row 8 merged successfully\n",
      "Row 9 merged successfully\n",
      "Row 10 merged successfully\n",
      "Row 11 merged successfully\n",
      "Row 12 merged successfully\n",
      "Row 13 merged successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231001.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231002.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231003.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231004.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231005.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231006.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231007.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231008.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231009.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231010.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231011.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231012.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231013.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231014.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231015.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231016.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231017.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231018.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231019.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231020.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231021.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231022.csv : Inserted successfully\n",
      "All CSV files are inserted\n",
      "Time spent: 53.136682987213135 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import ibm_db\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "import datetime as dt \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "conn = ibm_db.connect(\"DATABASE=AYB_APPL;HOSTNAME=10.143.16.244;PORT=50000;PROTOCOL=TCPIP;UID=IOT_DATA;PWD=asd23fgh;\", \"\", \"\")\n",
    "if conn:\n",
    "    print(\"Connected to the database\")\n",
    "\n",
    "    \n",
    "# 1) LOCATIONの最新のデータをINSERT/UPDATE\n",
    "\n",
    "#1.  最新フォルダの全CSVのPATHをまとめる。\n",
    "directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "file_pattern = '20*'  \n",
    "files = glob.glob(os.path.join(directory, file_pattern))\n",
    "files.sort()\n",
    "folder_path = files[-1]\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "\n",
    "\n",
    "#2. 最新のCSVファイルを探す。\n",
    "if csv_files:  \n",
    "    latest_csv_file = max(csv_files, key=os.path.getmtime)  \n",
    "    df = pd.read_csv(latest_csv_file, encoding='cp932',dtype= object)\n",
    " \n",
    "#3. CSVファイルのLocationカラムから最新の値を変数に入れる。\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    a = df['Location'].unique()\n",
    "    latest_data = pd.DataFrame()\n",
    "    df_concat = []\n",
    "    for location in a:\n",
    "        latest_location = df[df['Location'] == location].nlargest(1, 'Timestamp')\n",
    "        df_concat.append(latest_location)\n",
    "    latest_data = pd.concat(df_concat, ignore_index=True)\n",
    "    print(\"Latest CSV file:\", latest_csv_file)\n",
    "    \n",
    "else:\n",
    "    print(\"No CSV files found in the folder.\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# 4. データがあればUPDATE, データがなければINSERTする。\n",
    "merge_query = \"\"\"\n",
    "MERGE INTO LIQUID_PARTICLE_LAST AS target\n",
    "USING (SELECT ? AS LOCATION, ? AS TS_DT, ? AS VALUE_1_0, ? AS VALUE_3_0, ? AS VALUE_5_0, ? AS VALUE_10_0, ? AS VALUE_15_0, ? AS VALUE_20_0, ? AS VALUE_25_0, ? AS VALUE_50_0 FROM SYSIBM.SYSDUMMY1) AS source\n",
    "ON target.LOCATION = source.LOCATION\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET target.TS_DT = source.TS_DT, \n",
    "               target.VALUE_1_0 = source.VALUE_1_0, \n",
    "               target.VALUE_3_0 = source.VALUE_3_0, \n",
    "               target.VALUE_5_0 = source.VALUE_5_0, \n",
    "               target.VALUE_10_0 = source.VALUE_10_0, \n",
    "               target.VALUE_15_0 = source.VALUE_15_0, \n",
    "               target.VALUE_20_0 = source.VALUE_20_0, \n",
    "               target.VALUE_25_0 = source.VALUE_25_0, \n",
    "               target.VALUE_50_0 = source.VALUE_50_0\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (LOCATION, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0)\n",
    "    VALUES (source.LOCATION, source.TS_DT, source.VALUE_1_0, source.VALUE_3_0, source.VALUE_5_0, source.VALUE_10_0, source.VALUE_15_0, source.VALUE_20_0, source.VALUE_25_0, source.VALUE_50_0);\n",
    "\"\"\"\n",
    "\n",
    "stmt = ibm_db.prepare(conn, merge_query)\n",
    "\n",
    "for index, row in latest_data.iterrows():\n",
    "    location = row['Location']\n",
    "    timestamp = row['Timestamp']\n",
    "    c1 = row['1.0μｍ']\n",
    "    c3 = row['3.0μｍ']\n",
    "    c5 = row['5.0μｍ']\n",
    "    c10 = row['10.0μｍ']\n",
    "    c15 = row['15.0μｍ']\n",
    "    c20 = row['20.0μｍ']\n",
    "    c25 = row['25.0μｍ']\n",
    "    c50 = row['50.0μｍ']\n",
    "    \n",
    "    if ibm_db.execute(stmt, (location, timestamp, c1, c3, c5, c10, c15, c20, c25, c50)):\n",
    "        print(f\"Row {index + 1} merged successfully\")\n",
    "    else:\n",
    "        print(f\"Error merging row {index + 1}: {ibm_db.stmt_errormsg()}\")\n",
    "\n",
    "\n",
    "        \n",
    "#############################################################################################################\n",
    "        \n",
    "# 2) JSON記録に記載された日より、以降のデータをCSVファイルごとにINSERTする\n",
    "\n",
    "        \n",
    "#　1.JSONの記録からデータベースに最後INSERTされた時刻を取得する\n",
    "\n",
    "with open('insertion_time.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    inserted_time = dt.datetime.strptime(data['insertion_time'], '%Y-%m-%d %H:%M:%S')\n",
    "    inserted_day = inserted_time.strftime('%Y%m%d')\n",
    "    time_to_compare = data['insertion_time']\n",
    "\n",
    "    \n",
    "\n",
    "#  2.最新のフォルダから,全CSVのPATHをまとめる\n",
    "\n",
    "directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "file_pattern = '20*'  \n",
    "files = glob.glob(os.path.join(directory, file_pattern))\n",
    "files.sort()\n",
    "folder_path = files[-1]\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 　3.JSON記録に記載された日と、それより以降のCSV1をまとめる  \n",
    "selected_csv_files=[]\n",
    "selected_csv_files = [file for file in csv_files if int(file[-12:-4]) >= int(inserted_day)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   4.JSON記録に記載された日より以降のCSV1を１つずつINSERTする  \n",
    "if selected_csv_files:\n",
    "    \n",
    "    for i in selected_csv_files:\n",
    "        df = pd.read_csv(fr\"{i}\", encoding='cp932', dtype= object)\n",
    "        df['Timestamp'] = df['Timestamp'].str.replace('/', '-', regex=False)\n",
    "        \n",
    "        a = df[df['Timestamp'] >  time_to_compare]\n",
    "        data = tuple(tuple(row) for row in a.values )\n",
    "           \n",
    "        b = \"\"\n",
    "        for row in data:\n",
    "            b += str(row) +\",\"\n",
    "        b = b[:-1]\n",
    "        \n",
    "        insert_query = f\"INSERT INTO LIQUID_PARTICLE_TEST (Location, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0) VALUES {b}\"\n",
    "        stmt = ibm_db.prepare(conn, insert_query)\n",
    "        \n",
    "        try:\n",
    "            if ibm_db.execute(stmt, b):\n",
    "                print(f\"{i} : Inserted successfully\")     \n",
    "        except:\n",
    "            print(f\"({i}) is already updated\")\n",
    "                \n",
    "        \n",
    "#   5.時間を JSON ファイルに保存する   \n",
    "    \n",
    "        insertion_time = a['Timestamp'].max()\n",
    "        json_data = {'insertion_time': insertion_time}\n",
    "        with open('insertion_time.json', 'w') as json_file:\n",
    "            json.dump(json_data, json_file, indent=4)\n",
    "    print('All CSV files are inserted')\n",
    "elif not selected_csv_files:\n",
    "    print(\"Database is already updated\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time spent: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74237f-1662-4c7c-88d1-6614b49897b5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# if os.path.exists(json_file_path):\n",
    "#     with open(json_file_path, 'r') as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#         inserted_time = dt.datetime.strptime(data['insertion_time'], '%Y-%m-%d %H:%M:%S')\n",
    "#         inserted_day = inserted_time.strftime('%Y%m%d')\n",
    "#         time_to_compare = data['insertion_time']\n",
    "#         print(f\"Last Insertion time: {time_to_compare}\")\n",
    "#     directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "#     file_pattern = '20*'  \n",
    "#     files = glob.glob(os.path.join(directory, file_pattern))\n",
    "#     files.sort()\n",
    "#     folder_path = files[-1]\n",
    "#     csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "#     selected_csv_files=[]\n",
    "#     selected_csv_files = [file for file in csv_files if int(file[-12:-4]) >= int(inserted_day)]\n",
    "#     selected_csv_files\n",
    "# else:\n",
    "#     print(\"JSON file does not exist. All CSV files below are going to be inserted into the database.\")\n",
    "#     logging.info(\"JSON file does not exist. All CSV files below are going to be inserted into the database.\")\n",
    "#     directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "#     file_pattern = '20*'  \n",
    "#     files = glob.glob(os.path.join(directory, file_pattern))\n",
    "#     files.sort()\n",
    "#     folder_path = files[-1]\n",
    "#     selected_csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc7c3e9-4c35-4887-a944-9c9407fa3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import ibm_db\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "import datetime as dt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3742d76-5ba8-4e1e-b5d6-112bb8f787a9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231001.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231002.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231003.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231004.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231005.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231006.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231007.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231008.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231009.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231010.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231011.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231012.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231013.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231014.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231015.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231016.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231017.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231018.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231019.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231020.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231021.csv',\n",
       " 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\\\\20231022.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.  最新フォルダの全CSVのPATHをまとめる。\n",
    "def get_latest_folder_csv_paths(directory):\n",
    "    file_pattern = '20*'  \n",
    "    folders = glob.glob(os.path.join(directory, file_pattern))\n",
    "    folders.sort()\n",
    "    latest_folder = folders[-1]\n",
    "    csv_files = glob.glob(os.path.join(latest_folder, '*.csv'))\n",
    "    return csv_files\n",
    "\n",
    "    \n",
    "directory = r\"C:\\Users\\00220401626\\Desktop\\Ayabe\\FMS\\CsvData\"\n",
    "csv_files = get_latest_folder_csv_paths(directory)\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e8b99ce6-5a98-41ea-abc4-2ec3cd5bdaac",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>1.0μｍ</th>\n",
       "      <th>3.0μｍ</th>\n",
       "      <th>5.0μｍ</th>\n",
       "      <th>10.0μｍ</th>\n",
       "      <th>15.0μｍ</th>\n",
       "      <th>20.0μｍ</th>\n",
       "      <th>25.0μｍ</th>\n",
       "      <th>50.0μｍ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RP07</td>\n",
       "      <td>2023/10/01 00:01:23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RP09</td>\n",
       "      <td>2023/10/01 00:01:23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RP10</td>\n",
       "      <td>2023/10/01 00:01:22</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RP13</td>\n",
       "      <td>2023/10/01 00:01:25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RP04</td>\n",
       "      <td>2023/10/01 00:01:03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74875</th>\n",
       "      <td>RP03</td>\n",
       "      <td>2023/10/06 23:59:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74876</th>\n",
       "      <td>RP05</td>\n",
       "      <td>2023/10/06 23:59:33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74877</th>\n",
       "      <td>RP02</td>\n",
       "      <td>2023/10/06 23:59:32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74878</th>\n",
       "      <td>RP12</td>\n",
       "      <td>2023/10/06 23:57:44</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74879</th>\n",
       "      <td>RP12</td>\n",
       "      <td>2023/10/06 23:59:14</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74880 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Location            Timestamp 1.0μｍ 3.0μｍ 5.0μｍ 10.0μｍ 15.0μｍ 20.0μｍ  \\\n",
       "0         RP07  2023/10/01 00:01:23     0     0     0      0      0      0   \n",
       "1         RP09  2023/10/01 00:01:23     0     0     0      0      0      0   \n",
       "2         RP10  2023/10/01 00:01:22    18     3     0      0      0      0   \n",
       "3         RP13  2023/10/01 00:01:25     0     0     0      0      0      0   \n",
       "4         RP04  2023/10/01 00:01:03     0     0     0      0      0      0   \n",
       "...        ...                  ...   ...   ...   ...    ...    ...    ...   \n",
       "74875     RP03  2023/10/06 23:59:33     0     0     0      0      0      0   \n",
       "74876     RP05  2023/10/06 23:59:33     0     0     0      0      0      0   \n",
       "74877     RP02  2023/10/06 23:59:32     0     0     0      0      0      0   \n",
       "74878     RP12  2023/10/06 23:57:44     9     3     0      0      0      0   \n",
       "74879     RP12  2023/10/06 23:59:14    15     7     2      0      0      0   \n",
       "\n",
       "      25.0μｍ 50.0μｍ  \n",
       "0          0      0  \n",
       "1          0      0  \n",
       "2          0      0  \n",
       "3          0      0  \n",
       "4          0      0  \n",
       "...      ...    ...  \n",
       "74875      0      0  \n",
       "74876      0      0  \n",
       "74877      0      0  \n",
       "74878      0      0  \n",
       "74879      0      0  \n",
       "\n",
       "[74880 rows x 10 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def all_csv(path, file_extension='csv', encoding='cp932', parse_time=True):\n",
    "    csv_files = glob.glob(os.path.join(path, f'*.{file_extension}'))\n",
    "    data_frames = [pd.read_csv(file, encoding=encoding, dtype=object, parse_dates=parse_time) for file in csv_files]\n",
    "    df = pd.concat(data_frames, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "path = r\"C:\\Users\\00220401626\\Desktop\\Ayabe\\FMS\\CsvData\\2021\"\n",
    "df = all_csv(path, encoding='cp932', parse_time=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be1a432b-cc19-4624-924b-0bf5b84ef847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387af853-b4e5-4e19-9cd6-121149456f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
