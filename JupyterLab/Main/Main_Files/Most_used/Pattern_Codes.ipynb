{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6dc2d0-fe7e-4752-8218-e47f57069ec6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import ntpath\n",
    "import platform\n",
    "import posixpath\n",
    "import ftplib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5afcf6c-6d3e-4938-a7d7-19343a8a7611",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0ecee-6ec2-4a34-a3b1-d4ca21698464",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sample.csv'   , encoding='cp932', header=0, parse_dates=True, index_col='column', dtype=object,  sheet_name='sheet_name')\n",
    "df = pd.read_excel('sample.xlsx', encoding='cp932', header=0, parse_dates=True, index_col='column', dtype=object,  sheet_name='sheet_name')\n",
    "\n",
    "df.to_csv(\"file.xlsx\",   header = True, index=False, encoding=\"cp932\")\n",
    "df.to_excel(\"file.xlsx\", header = True, index=False, encoding=\"cp932\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6dd30-2f8f-492e-bb88-e6f2e7b6ca63",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = glob.glob(file_path + \"*.csv\")\n",
    "df_list = [pd.read_csv(r\"C:\\Users\\00220401626\\Desktop\\General.csv\", encoding = \"cp932\", index = False) for file in path]\n",
    "df = pd.concat(df_list, axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcdc714-d1e4-4930-a70c-e318fa089d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(os.path.join(local_csv,'*.csv'))\n",
    "dfs = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(fr\"{csv_file}\", encoding = 'cp932', dtype = object)\n",
    "    dfs.append(df)\n",
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1487c-13b0-4307-a470-455757451f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(folder_name +\"*.csv\")              \n",
    "dfs = []\n",
    "for file in files:\n",
    "    i = pd.read_csv(file, encoding=\"cp932\", index = False)\n",
    "    dfs.append(i)\n",
    "df = pd.concat(dfs, axis=0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320c35d-5698-4194-8cf7-0ec6999a641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "td=pd.DataFrame()\n",
    "for root, dirs, files in os.walk(r\"C:\\Users\\00220401626\\Desktop\\General.csv\"):\n",
    "    for i in files:\n",
    "        if i.endswith(\".csv\"):\n",
    "        full = os.path.join(root, i)\n",
    "        d=pd.read_csv(full,encoding=\"cp932\")\n",
    "        td=pd.concat([td,d], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52199e-560f-43c5-ab04-d7af13e31dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T\n",
    "df.head()\n",
    "df.tail()\n",
    "df.info()\n",
    "df.describe()\n",
    "df.shape\n",
    "df.count()\n",
    "df.dtypes\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275a639-05d8-443d-93e1-9a02df29dc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column'].min()\n",
    "df['column'].max()\n",
    "df['column'].mean()\n",
    "df['column'].median()\n",
    "df['column'].sum()\n",
    "df['column'].count()                                                                          # Count of non-null values\n",
    "df['column'].diff()                                                                           # Calculate the difference between previous and next \n",
    "df['column'].unique()\n",
    "df['column'].nunique()                                                                        # number of unique values\n",
    "df['column'].isna().sum()\n",
    "df['column'].isnull().sum()\n",
    "df['column'].notna().sum()\n",
    "df['column'].notnull().sum()\n",
    "df['column'].isin(['value1', 'value2'])\n",
    "df['column'].duplicated().sum()\n",
    "df['column'].tolist()\n",
    "a = df['column'].value_counts()['value1']\n",
    "a = (df['column'] == 'ABS').values.sum()\n",
    "a = df['column'].str.isspace()\n",
    "top_values = df['column'].nlargest(10)                                                        # top 10 values from the 'column'\n",
    "bottom_values = df['column'].nsmallest(10)                                                    # the bottom 10 values from the 'column'\n",
    "cumulative_sum_A = df['A'].cumsum()                                                           # Calculating the cumulative sum for column 'A'\n",
    "shifted_values = df['column'].shift(2)                                                        # Shift values in the 'column' by 1 period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286db134-e38c-4045-9ab7-e4ed6eff3daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('Time', inplace=True) \n",
    "df1= df.resample('D').nunique()                                                               # calculate the number of unique values for each day  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bd37fa1-56c6-41c6-a7ad-b0674b4b4a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture information: ('64bit', 'WindowsPE')\n",
      "Operating system version: 10.0.19045\n",
      "Machine type: AMD64\n",
      "Platform information: Windows-10-10.0.19045-SP0\n",
      "The underlying system is: Windows\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "arch_info = platform.architecture()\n",
    "print(f\"Architecture information: {arch_info}\")\n",
    "\n",
    "version = platform.version()\n",
    "print(f\"Operating system version: {version}\")\n",
    "\n",
    "machine_type = platform.machine()\n",
    "print(f\"Machine type: {machine_type}\")\n",
    "\n",
    "platform_info = platform.platform()\n",
    "print(f\"Platform information: {platform_info}\")\n",
    "\n",
    "system = platform.system()\n",
    "print(f\"The underlying system is: {system}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5953aea-f56d-4270-9342-829db0d307a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['A', 'B', 'C'], axis = 1, inplace = True)\n",
    "df.dropna(subset=['A'], inplace=True)\n",
    "df.drop_duplicates(subset=['A', 'B'], inplace = True)\n",
    "df.replace(\"Null\",np.nan)\n",
    "df.fillna(0, inplace=True)\n",
    "df[\"A\"].fillna(0, inplace = True)\n",
    "df['B'].fillna(df['B'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa801571-c48d-41be-8766-409b75ec2ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[0:3]\n",
    "df[:3]\n",
    "df[9:14]\n",
    "df[100:105]\n",
    "df['2020-08-15':'2020-09-14']\n",
    "\n",
    "df[df[\"column\"] == 'a']\n",
    "df[df['column'] == 2015]\n",
    "df[df['column'].isin([2010])]\n",
    "df[df['column'].isin(['A','B'])]\n",
    "df[df['column'].str.contains('a')]\n",
    "df[df['column'].str.startswith('b')]\n",
    "df[df['column'].str.endswith('c')]\n",
    "\n",
    "df['column'] = df['column'].str[-15:-4]                                              # belgilangan strni kesib oladi\n",
    "df['column'] = df['column'].str.strip()                                              # Remove each whitespace from column\n",
    "\n",
    "df[df['Column'] == 'Value'][['Column1', 'Column2']]\n",
    "\n",
    "df['column'].isin(['a']).sum()\n",
    "df[df['column1'] <= df['column2'].max()]\n",
    "df[(df['column_1'] == 2015) & (df['column_2'] == 'A')]\n",
    "df[(df['column_1'] == 2010) | (df['column_2'] == 2015)]\n",
    "df[(df[\"column_1\"] == 'a')  | (df[\"column_2\"] == '10') | (df[\"column_3\"] == '15')]\n",
    "\n",
    "df = df.loc[::step]\n",
    "df = df.loc[:,['column_1','column_2']]\n",
    "df = df.loc[(df['column_1'] >= a) & (df['column_2'] <= b)] \n",
    "df = df.loc[df['column_1'] > 20, ['column_2', 'column_3']]\n",
    "df.iloc[row_indices, column_indices]\n",
    "df = df.iloc[[1, 3], [0, 2]]\n",
    "df.iloc[:, 2] = 'new_column'                                                          # Rename column\n",
    "\n",
    "df[\"column\"] = df[\"column\"].astype(str)\n",
    "df[\"column\"] = df[\"column\"].astype(int)\n",
    "df[\"column\"] = df[\"column\"].astype(float)\n",
    "df['column'] = df['column'].apply(lambda x: x*2)\n",
    "\n",
    "df['City'] = df['City'].replace('Paris', 'Margilon')\n",
    "df = df['ColumnToSplit'].str.split(\" \", expand=True)                                 # bitta column ni ikkiga bo'ladi\n",
    "df[\"C\"] = df[\"A\"] + \"-\" + df[\"B\"]                                                    # ikkita column ni bittaga jamlash\n",
    "df[\"C\"] = df[\"A\"].astype(str) + \"-\" + df[\"B\"].astype(str)\n",
    "df['A'] = df['A'].str.strip()                                                        # remove whitespaces\n",
    "\n",
    "df = df.rename(columns={'a': 'A'})\n",
    "df.rename(columns={'column_1': '1', 'column_2': '2','column_3':'3'}, inplace=True)   # rename columns\n",
    "df.insert(loc=0, column=\"column_name\", value = str(100))                             # Convert the value to a string and insert it as the first column \n",
    "\n",
    "df['A'] = df[\"A\"].str.lstrip()\n",
    "df['A'] = df['A'].astype(float) / 1000\n",
    "df['A'] = df[\"A\"].str.split('_').str[0] \n",
    "df['A'] = df[\"A\"].str.split('_').str[1] \n",
    "\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m:%d %H:%M:%S')                              \n",
    "df['A'] = df['A'].dt.strftime('%Y-%m-%d %H:%M:%S')                                                        # Change datetime to string\n",
    "df['A'] = pd.to_datetime(df['A'],unit='ms').dt.strftime('%H:%M:%S:%f').str[:-3]\n",
    "df['A'] = df['A'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))                              # Change string to datetime\n",
    "df[\"A\"] = pd.to_datetime(df[\"A\"]) + pd.to_timedelta(df[\"A\"]/1000, \"S\")\n",
    "a = timedelta(days = 5, hours = 2, minutes = 30)                                                          # Creating Timedelta\n",
    "a = datetime.datetime(year=2017, month=10, day=10, hour=15)                                               # Cteating datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c08cff4a-90af-441b-9c01-52f3bb5bcd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='column', ascending=False, inplace=True)                                                # Sort by a single column in descending order\n",
    "df.sort_values(by='column', ascending=False, na_position='first', inplace=True)                           # Sort the DataFrame by the values of a specific column in descending order\n",
    "df.sort_values(by=['column_1', 'column_2'], ascending=False, inplace=True)                                # Sort by multiple columns in descending order\n",
    "df.sort_values(by=['column_1', 'column_2', 'column_3'], ascending=[False, True, False], inplace=True)     # Sort by multiple columns with different sorting orders\n",
    "df.sort_values(by=['column']).reset_index(drop=True)                                                      # Sort the DataFrame by 'column' and reset the index\n",
    "df.sort_index(ascending=False, inplace=True, na_position='first')                                         # Sort the DataFrame by the index in descending order with na_position specified\n",
    "df.reset_index(inplace=True)                                                                              #  Reset the index of the DataFrame\n",
    "df.loc[df['column'] == 100].reset_index(drop=True)                                                        #  Filter rows where 'column' equals a specific value and reset the index\n",
    "df.reindex(columns=['column_1', 'column_2','column_3'], inplace=True)\n",
    "df.set_index('column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed33163-ab48-4bf3-ae12-4f2c352616af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(items=['value_1' , 'value_2'], axis=0))                                                        \n",
    "df.filter(items=['column_1' , 'column_2'], axis=1))                                                      \n",
    "df.filter(items=['column_1', 'column_2']).filter(items=['value_1', 'value_2'], axis=0))                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251b1b0-9d1e-4663-8e13-fe5fed5e843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby['A'].min()\n",
    "df.groupby['A'].max()\n",
    "df.groupby('A').mean()\n",
    "df.groupby('A').max()\n",
    "df.groupby['A'].median()\n",
    "\n",
    "df['A'] = df.groupby(['B']).cumcount()+1                                      #Sequence number of each element starting from 1\n",
    "df['A'] = df.groupby(['B','C']).cumcount()                                    #Sequence number of each element starting from 0\n",
    "df[['A','B']].groupby(['C','A']).mean()\n",
    "df[['A','B']].groupby('C').agg(['mean','sum','count','max','min','std','var'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b26d43-f857-4f9b-9afc-1cf98b322a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.resample('H').max()\n",
    "df.resample('10D').sum()\n",
    "df.resample(\"D\").mean()\n",
    "df.resample('D').nunique()\n",
    "df.resample('D').count()\n",
    "df.resample(\"M\").sum()\n",
    "df.resample(\"Q\").agg([\"sum\", \"mean\", \"max\", \"min\"])\n",
    "df.resample('W').agg(['min', 'max', 'sum'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4961c8-2ff7-41ae-9f61-11b667d9e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot(index='...', columns='...', values='...')\n",
    "pd.pivot_table(df, values='...', index='...', columns='...', aggfunc='...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237545c5-e33b-4a4d-b8d6-e6d17d50997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df1, df2], axis=0, join='outer', ignore_index=True)\n",
    "pd.merge(left_df, right_df, on=...., how=...., left_on=....., right_on=....., left_index=......, right_index=.....)\n",
    "df = df1.join(df2, on='price', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c05d7-bb19-471d-a065-2a71983c2884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('year == 2010')\n",
    "df.query('year > 2010')\n",
    "df.query('column == A')\n",
    "df.query('column_1 == 2010 or column_2 == 2015')\n",
    "df.query('column == \"A\" and column == 2015')\n",
    "\n",
    "df = pd.RangeIndex(start=1, stop=len(d.index) + 1, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e486e919-90fb-4091-98b7-2fc66811d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "           A           B\n",
      "0  123456789  3456789012\n",
      "1  987654321  8765432109\n",
      "\n",
      "Formatted DataFrame:\n",
      "             A              B\n",
      "0  123,456,789  3,456,789,012\n",
      "1  987,654,321  8,765,432,109\n",
      "\n",
      "Formatted DataFrame with Commas Replaced by Spaces:\n",
      "             A              B\n",
      "0  123 456 789  3 456 789 012\n",
      "1  987 654 321  8 765 432 109\n"
     ]
    }
   ],
   "source": [
    "formatted_df = df.applymap('{:,.0f}'.format)                # Apply the formatting using applymap, har 3 ta qatorni vergul bilan ajratadi\n",
    "formatted_df = formatted_df.replace(',', ' ', regex=True)   # Replace commas with spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "186a8dc6-9728-4d17-b680-b01382a99511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numeric_column</th>\n",
       "      <th>binned_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>51-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110</td>\n",
       "      <td>101-150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>150+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>0-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90</td>\n",
       "      <td>51-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130</td>\n",
       "      <td>101-150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numeric_column binned_column\n",
       "0              20          0-50\n",
       "1              25          0-50\n",
       "2              75        51-100\n",
       "3             110       101-150\n",
       "4             160          150+\n",
       "5              40          0-50\n",
       "6              90        51-100\n",
       "7             130       101-150"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = {'numeric_column': [20, 25, 75, 110, 160, 40, 90, 130]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "bins = [0, 50, 100, 150, np.inf]\n",
    "labels = ['0-50', '51-100', '101-150', '150+']\n",
    "\n",
    "df['binned_column'] = pd.cut(df['numeric_column'], bins=bins, labels=labels)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4e1a6-eb1e-487e-9144-c1e1cd7e39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_csv_files = [file for file in csv_files if int(file[-12:-4]) >= int(inserted_day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b18230-cca5-460f-99cd-ffb7fa9a30bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\20231001.csv\", encoding='cp932', dtype=object, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f4b707-cc4d-4347-ae45-5b43c8d0a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamma CSV Filelarni bitta dataframega joylash\n",
    "path =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2023\"\n",
    "csv_files = glob.glob(os.path.join(path, '*.csv'))\n",
    "data_frames = []\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, encoding='cp932',dtype= object)\n",
    "    data_frames.append(df)\n",
    "concatenated_df = pd.concat(data_frames, ignore_index=True)\n",
    "concatenated_df['Timestamp'] = pd.to_datetime(concatenated_df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e13ad91-d7bb-490a-a7f9-cdc15d8f63c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = []\n",
    "for location in a:\n",
    "    latest_location = df[df['Location'] == location].nlargest(1, 'Timestamp')\n",
    "    df_concat.append(latest_location)\n",
    "latest_data = pd.concat(df_concat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fbab9-914a-4795-961f-7ef7fe0ec3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "file_pattern = '20*'  \n",
    "files = glob.glob(os.path.join(directory, file_pattern))\n",
    "files.sort()\n",
    "folder_path = files[-1]\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "latest_csv_file = max(csv_files, key=os.path.getmtime)\n",
    "df2 = pd.read_csv(latest_csv_file, encoding='cp932',dtype= object)\n",
    "df2['Timestamp'] = pd.to_datetime(df2['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02b3f6-384f-474c-8e7e-f3e280f9ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "json_filename = 'insertion_time.json'\n",
    "json_file_path = os.path.join(current_directory, json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f0b30fc-3d77-48f8-ac7b-fb6f3cfe353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Alice, Age: 25, City: New York\n",
      "Name: Bob, Age: 30, City: San Francisco\n",
      "Name: Charlie, Age: 35, City: Los Angeles\n"
     ]
    }
   ],
   "source": [
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['New York', 'San Francisco', 'Los Angeles']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "names = df['Name']\n",
    "ages = df['Age']\n",
    "cities = df['City']\n",
    "\n",
    "for name, age, city in zip(names, ages, cities):\n",
    "    print(f\"Name: {name}, Age: {age}, City: {city}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63461e78-94a8-40ae-b31d-046bf837be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT CSV FROM LOCAL \n",
    "df = pd.read_csv(r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2023\\20231001.csv\", encoding='cp932',dtype= object)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "638157ff-abb9-48bf-a346-bb5f430de734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_column</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>second</th>\n",
       "      <th>weekday_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-15 08:30:00</td>\n",
       "      <td>2023-01-15</td>\n",
       "      <td>08:30:00</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-20 15:45:30</td>\n",
       "      <td>2023-02-20</td>\n",
       "      <td>15:45:30</td>\n",
       "      <td>2023</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-25 18:20:45</td>\n",
       "      <td>2023-03-25</td>\n",
       "      <td>18:20:45</td>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime_column        date      time  year  month  day  hour  minute  \\\n",
       "0 2023-01-15 08:30:00  2023-01-15  08:30:00  2023      1   15     8      30   \n",
       "1 2023-02-20 15:45:30  2023-02-20  15:45:30  2023      2   20    15      45   \n",
       "2 2023-03-25 18:20:45  2023-03-25  18:20:45  2023      3   25    18      20   \n",
       "\n",
       "   second weekday_name  \n",
       "0       0       Sunday  \n",
       "1      30       Monday  \n",
       "2      45     Saturday  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'datetime_column': ['2023-01-15 08:30:00', '2023-02-20 15:45:30', '2023-03-25 18:20:45']}\n",
    "df = pd.DataFrame(data)\n",
    "df['datetime_column'] = pd.to_datetime(df['datetime_column'])\n",
    "\n",
    "df['date'] = df['datetime_column'].dt.date\n",
    "df['time'] = df['datetime_column'].dt.time\n",
    "df['year'] = df['datetime_column'].dt.year\n",
    "df['month'] = df['datetime_column'].dt.month\n",
    "df['day'] = df['datetime_column'].dt.day\n",
    "df['hour'] = df['datetime_column'].dt.hour\n",
    "df['minute'] = df['datetime_column'].dt.minute\n",
    "df['second'] = df['datetime_column'].dt.second\n",
    "df['weekday_name'] = df['datetime_column'].dt.day_name()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e62055-be05-4e04-a46d-9a8c06404abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'] = df['Words'].str[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07c762d0-ab05-4d51-abf4-442317f26238",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aaa',\n",
       " 'bbb',\n",
       " 'ccc',\n",
       " 'd',\n",
       " '111',\n",
       " '222',\n",
       " '333',\n",
       " 'wer',\n",
       " 'sdf',\n",
       " 'x',\n",
       " 'cc',\n",
       " 'hghgh',\n",
       " 'jfjfj',\n",
       " 'kfkfk']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "text = \"aaa bbb  ccc d 111 222 333 wer sdf x cc hghgh jfjfj kfkfk\"\n",
    "words = text.split()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91b88894-03df-4ecc-81b2-4aa8d39b5608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>Doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0        1\n",
       "0  John      Doe\n",
       "1  Jane    Smith\n",
       "2   Bob  Johnson"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'Column': ['John Doe', 'Jane Smith', 'Bob Johnson']}\n",
    "df = pd.DataFrame(data)\n",
    "split = df['Column'].str.split(\" \", expand=True)\n",
    "\n",
    "df = pd.concat([df, split], axis=1)\n",
    "split\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc26709a-7083-4f21-a386-b3da0cf67c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc123/apple,orange,banana/123/42 is the answer/word123/apple\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>extracted_numbers</th>\n",
       "      <th>split_columns</th>\n",
       "      <th>joined_columns</th>\n",
       "      <th>is_digit</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>replaced_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc123</td>\n",
       "      <td>123</td>\n",
       "      <td>[abc123]</td>\n",
       "      <td>a,b,c,1,2,3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>abc123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple,orange,banana</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[apple, orange, banana]</td>\n",
       "      <td>a,p,p,l,e,,,o,r,a,n,g,e,,,b,a,n,a,n,a</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>apple,orange,banana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "      <td>[123]</td>\n",
       "      <td>1,2,3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42 is the answer</td>\n",
       "      <td>42</td>\n",
       "      <td>[42 is the answer]</td>\n",
       "      <td>4,2, ,i,s, ,t,h,e, ,a,n,s,w,e,r</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42 is the answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>word123</td>\n",
       "      <td>123</td>\n",
       "      <td>[word123]</td>\n",
       "      <td>w,o,r,d,1,2,3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>word123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[apple]</td>\n",
       "      <td>a,p,p,l,e</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>fruit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                column extracted_numbers            split_columns  \\\n",
       "0               abc123               123                 [abc123]   \n",
       "1  apple,orange,banana               NaN  [apple, orange, banana]   \n",
       "2                  123               123                    [123]   \n",
       "3     42 is the answer                42       [42 is the answer]   \n",
       "4              word123               123                [word123]   \n",
       "5                apple               NaN                  [apple]   \n",
       "\n",
       "                          joined_columns  is_digit  is_alpha  \\\n",
       "0                            a,b,c,1,2,3     False     False   \n",
       "1  a,p,p,l,e,,,o,r,a,n,g,e,,,b,a,n,a,n,a     False     False   \n",
       "2                                  1,2,3      True     False   \n",
       "3        4,2, ,i,s, ,t,h,e, ,a,n,s,w,e,r     False     False   \n",
       "4                          w,o,r,d,1,2,3     False     False   \n",
       "5                              a,p,p,l,e     False      True   \n",
       "\n",
       "       replaced_values  \n",
       "0               abc123  \n",
       "1  apple,orange,banana  \n",
       "2               number  \n",
       "3     42 is the answer  \n",
       "4              word123  \n",
       "5                fruit  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'column': ['abc123', 'apple,orange,banana', '123', '42 is the answer', 'word123', 'apple']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the operations\n",
    "df['extracted_numbers'] = df['column'].str.extract(r'(\\d+)')\n",
    "df['split_columns'] = df['column'].str.split(',')\n",
    "df['joined_columns'] = df['column'].str.join(',')\n",
    "df['is_digit'] = df['column'].str.isdigit()\n",
    "df['is_alpha'] = df['column'].str.isalpha()\n",
    "df['replaced_values'] = df['column'].replace({'apple': 'fruit', '123': 'number'})\n",
    "result = df['column'].str.cat(sep='/')\n",
    "print(result)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08744ba8-5b0e-4bae-851d-b7cb16acefad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>phone_number</th>\n",
       "      <th>apartment_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phone number is 123-456-7890 Apartment AAAA111...</td>\n",
       "      <td>123-456-7890</td>\n",
       "      <td>AAAA1111222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live at 456 Main Street, Apartment 3B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  phone_number  \\\n",
       "0  Phone number is 123-456-7890 Apartment AAAA111...  123-456-7890   \n",
       "1            I live at 456 Main Street, Apartment 3B           NaN   \n",
       "\n",
       "  apartment_number  \n",
       "0      AAAA1111222  \n",
       "1               3B  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'text': ['Phone number is 123-456-7890 Apartment AAAA1111222','I live at 456 Main Street, Apartment 3B']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['phone_number'] = df['text'].str.extract(r'(\\d{3}-\\d{3}-\\d{4})')\n",
    "df['apartment_number'] = df['text'].str.extract(r'Apartment (\\w+)')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9da27e8b-bdff-4e02-af11-5889a42f6497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple', 'banana', 'cherry']\n",
      "apple\n"
     ]
    }
   ],
   "source": [
    "text = \"apple_banana_cherry\"\n",
    "result = text.split('_')\n",
    "print(result)\n",
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f1084-2040-46a5-a938-7cb8bbae4668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd56ab-56fc-4b05-b63f-9676ab7d85f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "str.split('_')\n",
    "str.replace('this','with this')\n",
    "str.contains('a')\n",
    "str.startswith('b','c')\n",
    "str.endswith('b','c')\n",
    "str.upper()\n",
    "str.lower()\n",
    "-----------------------------------------------------------\n",
    "str.islower()\n",
    "str.isupper()\n",
    "str.capitalize()\n",
    "str.title()\n",
    "------------------------------------------------------------\n",
    "df.iloc[0,0]                # first location\n",
    "df.iloc[0,0] = '22'\n",
    "df.loc['c', 'two']         # row c and column two\n",
    "df.loc['c', 'two'] = 33 \n",
    "df.loc['a':'c']            # rows a to c\n",
    "df.loc['b':'d', 'two']     # rows b to d and column two \n",
    "df.loc[:, 'C':'E']         # all rows from C to E column\n",
    "df.loc[df[\"gender\"] == \"male\",\"gender\"] = 0\n",
    "df.loc[df[\"gender\"] == \"female\",\"gender\"] = 1\n",
    "----------------------------------------------------------\n",
    "df.drop_duplicates(subset=['A'], keep='last')\n",
    "df.drop([0,4], inplace=True)\n",
    "df.dropna()\n",
    "df.dropna(subset = ['C')]\n",
    "df.fillna(1)\n",
    "df.groupby('Group')['ID'].nunique()\n",
    "pd.unique(df['A']).tolist()\n",
    "df[df['A'] == 1]['B'].tolist()\n",
    "-------------------------------------------------------------\n",
    "df['count_B']=df.groupby(['group1','group2']).B.transform('count')\n",
    "df.groupby(['A','B']).mean()\n",
    "df.groupby(['A','B']).agg(['count', 'mean'])\n",
    "for jinsi, data in df.groupby('Jinsi'):\n",
    " data.to_csv(\"{}.csv\".format(jinsi))\n",
    "------------------------------------------------------------\n",
    "df[:10] # same as df.head(10)\n",
    "df[-10:] # same as df.tail(10)\n",
    "\n",
    "-----------------------------------------------------------\n",
    "for index, row in df.iterrows()\n",
    "----------------------------------------------------------\n",
    "list1 = [1, 2, 3, 4]\n",
    "list2 = ['a', 'b', 'c', 'd']\n",
    "list3 = [10, 20, 15, 30]\n",
    "# Use zip to combine the lists\n",
    "zipped = zip(list1, list2, list3)\n",
    "zipped_list = list(zipped)\n",
    "print(zipped_list)\n",
    "---------------------------------------------------------\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "c = [x+y for (x,y) in zip(a,b)]\n",
    "---------------------------------------------------------\n",
    "zipped_list = [(1, 'a',1), (2, 'b',3), (3, 'c',4), (4, 'd',5)]\n",
    "list1, list2, list3 = zip(*zipped_list)\n",
    "-------------------------------------------------------------------\n",
    "del df['C']\n",
    "df.drop(df.columns[[0, 2]], axis='columns')\n",
    "df.drop(['B', 'E'], axis='columns', inplace=True)\n",
    "-----------------------------------------------------------------\n",
    "df.rename(columns={'old_name_1': 'new_name_1', 'old_name_2': 'new_name_2'}, inplace=True)\n",
    "df['C'] = df['A'] + df['B']\n",
    "-------------------------------------------------------------------\n",
    "re_order_column = ['B', 'C', 'A']\n",
    "df = df[re_column]\n",
    "----------------------------------------------------------------------\n",
    "def countdown(n):\n",
    "    while n > 0:\n",
    "        yield n\n",
    "        n -= 1\n",
    "for i in countdown(5):\n",
    "    print(i)\n",
    "------------------------------------------------------------------\n",
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d250882a-29b0-498d-a1b4-0274fe460e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "file_pattern = '20*'  \n",
    "files = glob.glob(os.path.join(directory, file_pattern))\n",
    "files.sort()\n",
    "folder_path = files[-1]\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e4c855-412b-43cb-ac22-f0715f0b7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    num1 = float(input(\"Enter the numerator: \"))\n",
    "    num2 = float(input(\"Enter the denominator: \"))\n",
    "    result = divide_numbers(num1, num2)\n",
    "    if result is not None:\n",
    "        print(f\"Result: {result}\")\n",
    "except ValueError:\n",
    "    print(\"Error: Please enter valid numeric values.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n",
    "finally:\n",
    "    print(\"Execution completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd93960-490e-4d81-9bb4-44167eede6c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Example 1: SyntaxError\n",
    "    print(\"Hello, world!\"\n",
    "\n",
    "    # Example 2: IndentationError\n",
    "    if True:\n",
    "    print(\"Indentation is incorrect.\")\n",
    "\n",
    "    # Example 3: TypeError\n",
    "    result = 10 + \"5\"\n",
    "\n",
    "    # Example 4: NameError\n",
    "    print(undefined_variable)\n",
    "\n",
    "    # Example 5: ValueError\n",
    "    number = int(\"abc\")\n",
    "\n",
    "    # Example 6: ZeroDivisionError\n",
    "    result = 10 / 0\n",
    "\n",
    "    # Example 7: FileNotFoundError\n",
    "    with open(\"nonexistent_file.txt\", \"r\") as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Example 8: IndexError\n",
    "    my_list = [1, 2, 3]\n",
    "    print(my_list[5])\n",
    "\n",
    "    # Example 9: KeyError\n",
    "    my_dict = {'a': 1, 'b': 2}\n",
    "    value = my_dict['c']\n",
    "\n",
    "    # Example 10: AttributeError\n",
    "    x = \"hello\"\n",
    "    length = x.length\n",
    "\n",
    "except SyntaxError as e:\n",
    "    print(f\"SyntaxError: {e}\")\n",
    "except IndentationError as e:\n",
    "    print(f\"IndentationError: {e}\")\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")\n",
    "except NameError as e:\n",
    "    print(f\"NameError: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")\n",
    "except ZeroDivisionError as e:\n",
    "    print(f\"ZeroDivisionError: {e}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"FileNotFoundError: {e}\")\n",
    "except IndexError as e:\n",
    "    print(f\"IndexError: {e}\")\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")\n",
    "except AttributeError as e:\n",
    "    print(f\"AttributeError: {e}\")\n",
    "\n",
    "finally:\n",
    "    print(\"This will always be executed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a8618e-43fb-42e9-9a29-c7aac1a9e9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################SQL###################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678e81b-44fc-4974-940a-a696266f72a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "logging.debug('Detailed information, typically of interest only when diagnosing problems')\n",
    "logging.info('Confirmation that things are working as expected.')\n",
    "logging.warning('Indication that something unexpected happened or an issue might arise soon The software is still functioning as expected.')\n",
    "logging.error('Indicates a more serious problem, the software is unable to perform some function.')\n",
    "logging.critical(' A very serious error, indicating that the program itself may be unable to continue running.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b36fbe-1d75-47f1-af33-da2002499cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"  SELECT 列名\n",
    "\"     FROM 表名          \n",
    "\"     WHERE 検索条件                  # 検索条件を指定します。\n",
    "\"     GROUP BY 列名                   # 行のグループの特性を調べる\n",
    "\"     HAVING 検索条件                 # GROUP BY 文節に基づいて選択されるグループに対し、検索条件を指定します\n",
    "\"     ORDER BY 列名                   # ユーザーが希望する順番を指定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac34906-b17e-4c35-8db8-3628bd29f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat Table\n",
    "CREATE TABLE CONDUCTIVITY (\n",
    "    EQP_ID VARCHAR(8) NOT NULL,\n",
    "    UNIT_NUM VARCHAR(3) NOT NULL,\n",
    "    DATE_TIME TIMESTAMP NOT NULL,\n",
    "    VALUE DECIMAL(6,5),\n",
    "    PRIMARY KEY (EQP_ID, UNIT_NUM, DATE_TIME)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f800a8fa-2e01-4bd4-8379-d746cf1f360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect DB\n",
    "conn = ibm_db.connect(\"DATABASE=AYB_APPL;HOSTNAME=10.143.16.244;PORT=50000;PROTOCOL=TCPIP;UID=IOT_DATA;PWD=asd23fgh;\", \"\", \"\")\n",
    "if conn:\n",
    "    print(\"Connected to the database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d7341-2531-4863-8b07-cc969cc8ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "delete_query = \"DELETE FROM CONDUCTIVITY\"\n",
    "try:\n",
    "    ibm_db.autocommit(conn, ibm_db.SQL_AUTOCOMMIT_OFF)\n",
    "    if ibm_db.exec_immediate(conn, delete_query):\n",
    "        print(\"Existing data deleted successfully\")\n",
    "    ibm_db.commit(conn)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    ibm_db.rollback(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04acc72e-946e-415f-a5f2-5760d9ec5452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE with WHERE\n",
    "delete_query = \"DELETE FROM LIQUID_PARTICLE_TEST \n",
    "\n",
    "try:\n",
    "    ibm_db.autocommit(conn, ibm_db.SQL_AUTOCOMMIT_OFF)\n",
    "    if ibm_db.exec_immediate(conn, delete_query):\n",
    "        print(\"Selected rows deleted successfully\")\n",
    "\n",
    "    ibm_db.commit(conn)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    ibm_db.rollback(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c029a07e-1add-464e-9994-f7f623dd75c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECT \n",
    "\n",
    "sql_query = \"SELECT * FROM CONDUCTIVITY\"\n",
    "stmt = ibm_db.exec_immediate(conn, sql_query)\n",
    "\n",
    "data = []\n",
    "row = ibm_db.fetch_assoc(stmt)\n",
    "\n",
    "while row:\n",
    "    data.append(row)\n",
    "    row = ibm_db.fetch_assoc(stmt)\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af318e-d172-4ece-9ebd-2a7d41b15c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE TWO TABLE\n",
    "MERGE INTO CONDUCTIVITY AS TGT\n",
    "USING (\n",
    "    VALUES \n",
    "        ('LEV50001', '020', TIMESTAMP '2023-12-04 15:01:09', 233),\n",
    "        ('LEV50001', '020', TIMESTAMP '2023-12-02 15:01:39', 4.00000),\n",
    "        ('LEV50001', '020', TIMESTAMP '2023-12-03 15:02:09', 5.00000)\n",
    ") AS INSERTDATA (EQP_ID, UNIT_NUM, DATE_TIME, COND_VALUES)\n",
    "ON (\n",
    "    TGT.EQP_ID = INSERTDATA.EQP_ID \n",
    "    AND TGT.UNIT_NUM = INSERTDATA.UNIT_NUM \n",
    "    AND TGT.DATE_TIME = INSERTDATA.DATE_TIME\n",
    ")\n",
    "WHEN MATCHED THEN \n",
    "    UPDATE SET TGT.COND_VALUES = INSERTDATA.COND_VALUES\n",
    "WHEN NOT MATCHED THEN \n",
    "    INSERT (EQP_ID, UNIT_NUM, DATE_TIME, COND_VALUES) \n",
    "    VALUES (INSERTDATA.EQP_ID, INSERTDATA.UNIT_NUM, INSERTDATA.DATE_TIME, INSERTDATA.COND_VALUES);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4cecbb-1ecc-47ae-b9fb-1cd8698cefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. データがあればUPDATE, データがなければINSERTする。\n",
    "MERGE INTO LIQUID_PARTICLE_LAST AS target\n",
    "USING (SELECT ? AS LOCATION, ? AS TS_DT, ? AS VALUE_1_0, ? AS VALUE_3_0, ? AS VALUE_5_0, ? AS VALUE_10_0, ? AS VALUE_15_0, ? AS VALUE_20_0, ? AS VALUE_25_0, ? AS VALUE_50_0 FROM SYSIBM.SYSDUMMY1) AS source\n",
    "ON target.LOCATION = source.LOCATION\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET target.TS_DT = source.TS_DT, \n",
    "               target.VALUE_1_0 = source.VALUE_1_0, \n",
    "               target.VALUE_3_0 = source.VALUE_3_0, \n",
    "               target.VALUE_5_0 = source.VALUE_5_0, \n",
    "               target.VALUE_10_0 = source.VALUE_10_0, \n",
    "               target.VALUE_15_0 = source.VALUE_15_0, \n",
    "               target.VALUE_20_0 = source.VALUE_20_0, \n",
    "               target.VALUE_25_0 = source.VALUE_25_0, \n",
    "               target.VALUE_50_0 = source.VALUE_50_0\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (LOCATION, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0)\n",
    "    VALUES (source.LOCATION, source.TS_DT, source.VALUE_1_0, source.VALUE_3_0, source.VALUE_5_0, source.VALUE_10_0, source.VALUE_15_0, source.VALUE_20_0, source.VALUE_25_0, source.VALUE_50_0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e0fd27-ad6b-4856-86ec-1a32209a1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\\\Users\\\\00220401626\\\\Desktop\\\\FMS\\\\CsvData\\\\2023\\\\20231001.csv', encoding='cp932', dtype=object)\n",
    "df=df.iloc[:12000,::]\n",
    "\n",
    "df['Timestamp'] = df['Timestamp'].str.replace('/', '-', regex=False) \n",
    "\n",
    "data = tuple(tuple(row) for row in df.values )\n",
    "       \n",
    "b = \"\"\n",
    "for row in data:\n",
    "    b += str(row) +\",\"\n",
    "b = b[:-1]\n",
    "insert_query = f\"INSERT INTO LIQUID_PARTICLE_TEST (Location, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0) VALUES {b}\"\n",
    "stmt = ibm_db.prepare(conn, insert_query)\n",
    "if ibm_db.execute(stmt,b):\n",
    "    print(\"Inserted successfully\")\n",
    "else:\n",
    "    print(\"Already updated\")\n",
    "    \n",
    "insertion_time = df['Timestamp'].max()\n",
    "json_data = {'insertion_time': insertion_time}\n",
    "with open('insertion_time.json', 'w') as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6079a75-b26d-41d7-804f-4ca5bf974894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. データがあればUPDATE, データがなければINSERTする\n",
    "\n",
    "merge_query = \"\"\"\n",
    "MERGE INTO LIQUID_PARTICLE_LAST AS target\n",
    "USING (SELECT ? AS LOCATION, ? AS TS_DT, ? AS VALUE_1_0, ? AS VALUE_3_0, ? AS VALUE_5_0, ? AS VALUE_10_0, ? AS VALUE_15_0, ? AS VALUE_20_0, ? AS VALUE_25_0, ? AS VALUE_50_0 FROM SYSIBM.SYSDUMMY1) AS source\n",
    "ON target.LOCATION = source.LOCATION\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET target.TS_DT = source.TS_DT, \n",
    "               target.VALUE_1_0 = source.VALUE_1_0, \n",
    "               target.VALUE_3_0 = source.VALUE_3_0, \n",
    "               target.VALUE_5_0 = source.VALUE_5_0, \n",
    "               target.VALUE_10_0 = source.VALUE_10_0, \n",
    "               target.VALUE_15_0 = source.VALUE_15_0, \n",
    "               target.VALUE_20_0 = source.VALUE_20_0, \n",
    "               target.VALUE_25_0 = source.VALUE_25_0, \n",
    "               target.VALUE_50_0 = source.VALUE_50_0\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (LOCATION, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0)\n",
    "    VALUES (source.LOCATION, source.TS_DT, source.VALUE_1_0, source.VALUE_3_0, source.VALUE_5_0, source.VALUE_10_0, source.VALUE_15_0, source.VALUE_20_0, source.VALUE_25_0, source.VALUE_50_0);\n",
    "\"\"\"\n",
    "\n",
    "stmt = ibm_db.prepare(conn, merge_query)\n",
    "\n",
    "for index, row in latest_data.iterrows():\n",
    "    location = row['Location']\n",
    "    timestamp = row['Timestamp']\n",
    "    c1 = row['1.0μｍ']\n",
    "    c3 = row['3.0μｍ']\n",
    "    c5 = row['5.0μｍ']\n",
    "    c10 = row['10.0μｍ']\n",
    "    c15 = row['15.0μｍ']\n",
    "    c20 = row['20.0μｍ']\n",
    "    c25 = row['25.0μｍ']\n",
    "    c50 = row['50.0μｍ']\n",
    "    \n",
    "    if ibm_db.execute(stmt, (location, timestamp, c1, c3, c5, c10, c15, c20, c25, c50)):\n",
    "        print(f\"Row {index + 1} merged successfully\")\n",
    "    else:\n",
    "        print(f\"Error merging row {index + 1}: {ibm_db.stmt_errormsg()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac902b6-988c-4f01-acef-ce13c91a1fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSERT\n",
    "\n",
    "insert_query = \"INSERT INTO LIQUID_PARTICLE (LOCATION, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\n",
    "\n",
    "insert = ibm_db.prepare(conn, insert_query)\n",
    "for index, row in df.iterrows():\n",
    "    location = row['Location']\n",
    "    timestamp = row['Timestamp']\n",
    "    c1 = row['1.0μｍ']\n",
    "    c3 = row['3.0μｍ']\n",
    "    c5 = row['5.0μｍ']\n",
    "    c10 = row['10.0μｍ']\n",
    "    c15 = row['15.0μｍ']\n",
    "    c20 = row['20.0μｍ']\n",
    "    c25 = row['25.0μｍ']\n",
    "    c50 = row['50.0μｍ']\n",
    "\n",
    "    if ibm_db.execute(insert, (location, timestamp, c1, c3, c5, c10, c15, c20, c25, c50)):\n",
    "        print(f\"Row {index + 1} inserted successfully\")\n",
    "    else:\n",
    "        print(f\"Error inserting row {index + 1}: {ibm_db.stmt_errormsg()}\")\n",
    "print('All Rows are inserted')\n",
    "ibm_db.commit(conn)\n",
    "ibm_db.close(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8029c-708a-4be2-8582-515ad57f6fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE\n",
    "update_query = \"UPDATE table_name SET column1 = ? WHERE column2 = ?\"\n",
    "new_value = \"new_value\"\n",
    "where_value = \"some_condition\"\n",
    "params = (new_value, where_value)  \n",
    "stmt = ibm_db.prepare(conn, update_query)\n",
    "ibm_db.execute(stmt, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "724436a7-8ece-4a92-8d23-fed86f060cbe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(data, json_file, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJSON file \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m created successfully.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Create JSON file\n",
    "data = {\n",
    "    \"database\": \"AYB_APPL\",\n",
    "    \"hostname\": \"10.143.16.244\",\n",
    "    \"port\": \"50000\",\n",
    "    \"protocol\": \"TCPIP\",\n",
    "    \"uid\": \"IOT_DATA\",\n",
    "    \"pwd\": \"asd23fgh\",\n",
    "    \"directory\":r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "}\n",
    "\n",
    "\n",
    "file_path = 'config.json'\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f'JSON file \"{file_path}\" created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac587a49-baf1-4eb2-a604-ed62d6f2e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file \"C:\\Users\\00220401626\\Desktop\\Conductivity1.json\" created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Create JSON file\n",
    "data = {\n",
    "  \"comment\": \"\",\n",
    "  \"unit_num\": \"020\",\n",
    "  \"pw\": \"asd23fgh\",\n",
    "  \"eqp_id\": \"LEV10001\",\n",
    "  \"unit_name\": \"酸・アルカリ洗浄\",\n",
    "  \"dst_dir\": \"/IoT/bin/ftp/tmp/020/Conductivity/*/*CSV\",\n",
    "  \"database\": \"AYB_APPL\",\n",
    "  \"username\": \"IOT_DATA\",\n",
    "  \"server\": \"10.143.16.244\",\n",
    "  \"schema\": \"IOT_DATA\",\n",
    "  \"table\": \"CONDUCTIVITY\"\n",
    "}\n",
    "\n",
    "\n",
    "file_path = r'C:\\Users\\00220401626\\Desktop\\Conductivity1.json'\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f'JSON file \"{file_path}\" created successfully.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edcee75b-7d0a-4db2-81a2-b68d090b98cc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Japanese words extracted from PDF and exported to C:\\Users\\00220401626\\Desktop\\Words\\Muhim_Pdf\\list.csv\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def extract_japanese_words_from_pdf(pdf_path):\n",
    "    words_list = []\n",
    "    with fitz.open(pdf_path) as pdf_document:\n",
    "        for page_num in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_num]\n",
    "            text = page.get_text()\n",
    "            japanese_words = re.findall(r'[ぁ-んァ-ン一-龥ー]+', text)\n",
    "            words_list.extend(japanese_words)\n",
    "    return words_list\n",
    "\n",
    "def filter_and_export_to_csv(words_list, output_csv_path):\n",
    "    filtered_words = sorted(words_list, key=len)\n",
    "    df = pd.DataFrame({'Japanese Words': filtered_words})\n",
    "    df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = r'C:\\Users\\00220401626\\Desktop\\スマートFA\\データベース入門 配布資料\\01_補足資料\\③GROUP BYの補足.pdf'\n",
    "    output_csv_path = r'C:\\Users\\00220401626\\Desktop\\Words\\Muhim_Pdf\\list.csv'\n",
    "    japanese_words_list = extract_japanese_words_from_pdf(pdf_path)\n",
    "\n",
    "    filter_and_export_to_csv(japanese_words_list, output_csv_path)\n",
    "\n",
    "    print(f\"Japanese words extracted from PDF and exported to {output_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77d7bb65-194d-4224-83f2-b49b6e69f5ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "© 2023\n",
      "京セラグループ社員向け\n",
      "セラミックキッチン用品\n",
      "WEB特別販売会\n",
      "2023年\n",
      "2024年\n",
      "12/1金  ～ 1/31水\n",
      "実 施\n",
      "期 間\n",
      "購 入\n",
      "場 所\n",
      "楽天市場にて販売\n",
      "✓自宅直送 ✓楽天ポイント付与\n",
      "✓送料無料（一部商品を除く）\n",
      "グ レ ー ( I H 対 応 品 ) 購 入 １ 枚 に つ き\n",
      "「 ポ テ ト ン グ ミ ニ 」 １ つ プ レ ゼ ン ト\n",
      "30%\n",
      "OFF\n",
      "¥3,234(税込)～\n",
      "通 常 価 格  ¥4,620（ 税 込 ） ～\n",
      "セ ラ ブ リ ッ ド\n",
      "フ ラ イ パ ン 各 種\n",
      "パ ッ ケ ー ジ 切 替 の た め 特 別 価 格\n",
      "¥9,636(税込)～\n",
      "通 常 価 格  ¥16,060（ 税 込 ） ～\n",
      "40%\n",
      "OFF\n",
      "2 本 セ ッ ト （ 1 2 . 5 / 1 4 c m ）\n",
      "3 本 セ ッ ト （ 1 2 . 5 / 1 4 / 1 6 c m ）\n",
      "ココチカル セラミックナイフ\n",
      "そ の 他 , 福 袋 や ボ ト ル な ど セ ー ル 品 を 多 数 ご 用 意 し て お り ま す 。\n",
      "※ 在 庫 売 り 切 り 商 品 も ご ざ い ま す 。\n",
      "69%\n",
      "OFF\n",
      "MAX\n",
      "※ご購入は京セラグループ社員限定とさせていただきますので、\n",
      "　京セラグループ社員以外への情報共有はご遠慮ください。\n",
      "※楽天市場にない商品もクーポン使用で30%OFFにてお買い求めいただけます。\n",
      "京セラキッチン\n",
      "オンラインストア\n",
      "全品 30%OFF\n",
      "I D：kyocera-apd\n",
      "PW：kyocera2312\n",
      "京セラキッチン\n",
      "楽天市場店\n",
      "クーポンコード\n",
      "kyocera2312\n",
      "京セラキッチン\n",
      "オンラインストア\n",
      "同時開催\n",
      "指\n",
      "を\n",
      "汚\n",
      "さ\n",
      "ず\n",
      "食\n",
      "べ\n",
      "ら\n",
      "れ\n",
      "る\n",
      "ポ\n",
      "テ\n",
      "ト\n",
      "チ\n",
      "ッ\n",
      "プ\n",
      "ス\n",
      "専\n",
      "用\n",
      "ト\n",
      "ン\n",
      "グ\n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import fitz \n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = ''\n",
    "    with fitz.open(pdf_path) as pdf_document:\n",
    "        for page_number in range(pdf_document.page_count):\n",
    "            page = pdf_document[page_number]\n",
    "            text += page.get_text(\"text\")  \n",
    "            print(text)\n",
    "\n",
    "    return text\n",
    "    \n",
    "pdf_text = extract_text_from_pdf(r'C:\\Users\\00220401626\\Desktop\\Words\\Muhim_Pdf\\2312_社販チラシ_WEB.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "469eb8f4-79c1-4a40-b48c-86622a10a5c9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['©',\n",
       " ' ',\n",
       " '2023',\n",
       " '\\n',\n",
       " '京セラ',\n",
       " 'グループ',\n",
       " '社員',\n",
       " '向け',\n",
       " '\\n',\n",
       " 'セラミック',\n",
       " 'キッチン',\n",
       " '用品',\n",
       " '\\n',\n",
       " 'WEB',\n",
       " '特別',\n",
       " '販売',\n",
       " '会',\n",
       " '\\n',\n",
       " '2023',\n",
       " '年',\n",
       " '\\n',\n",
       " '2024',\n",
       " '年',\n",
       " '\\n',\n",
       " '12',\n",
       " '/',\n",
       " '1',\n",
       " '金',\n",
       " '  ',\n",
       " '～',\n",
       " ' ',\n",
       " '1',\n",
       " '/',\n",
       " '31',\n",
       " '水',\n",
       " '\\n',\n",
       " '実',\n",
       " ' ',\n",
       " '施',\n",
       " '\\n',\n",
       " '期',\n",
       " ' ',\n",
       " '間',\n",
       " '\\n',\n",
       " '購',\n",
       " ' ',\n",
       " '入',\n",
       " '\\n',\n",
       " '場',\n",
       " ' ',\n",
       " '所',\n",
       " '\\n',\n",
       " '楽天',\n",
       " '市場',\n",
       " 'にて',\n",
       " '販売',\n",
       " '\\n',\n",
       " '✓',\n",
       " '自宅',\n",
       " '直送',\n",
       " ' ',\n",
       " '✓',\n",
       " '楽天',\n",
       " 'ポイント',\n",
       " '付与',\n",
       " '\\n',\n",
       " '✓',\n",
       " '送料',\n",
       " '無料',\n",
       " '（',\n",
       " '一部',\n",
       " '商品',\n",
       " 'を',\n",
       " '除く',\n",
       " '）',\n",
       " '\\n',\n",
       " 'グ',\n",
       " ' ',\n",
       " 'レ',\n",
       " ' ',\n",
       " 'ー',\n",
       " ' ',\n",
       " '(',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'H',\n",
       " ' ',\n",
       " '対',\n",
       " ' ',\n",
       " '応',\n",
       " ' ',\n",
       " '品',\n",
       " ' ',\n",
       " ')',\n",
       " ' ',\n",
       " '購',\n",
       " ' ',\n",
       " '入',\n",
       " ' ',\n",
       " '１',\n",
       " ' ',\n",
       " '枚',\n",
       " ' ',\n",
       " 'に',\n",
       " ' ',\n",
       " 'つ',\n",
       " ' ',\n",
       " 'き',\n",
       " '\\n',\n",
       " '「',\n",
       " ' ',\n",
       " 'ポ',\n",
       " ' ',\n",
       " 'テ',\n",
       " ' ',\n",
       " 'ト',\n",
       " ' ',\n",
       " 'ン',\n",
       " ' ',\n",
       " 'グ',\n",
       " ' ',\n",
       " 'ミ',\n",
       " ' ',\n",
       " 'ニ',\n",
       " ' ',\n",
       " '」',\n",
       " ' ',\n",
       " '１',\n",
       " ' ',\n",
       " 'つ',\n",
       " ' ',\n",
       " 'プ',\n",
       " ' ',\n",
       " 'レ',\n",
       " ' ',\n",
       " 'ゼ',\n",
       " ' ',\n",
       " 'ン',\n",
       " ' ',\n",
       " 'ト',\n",
       " '\\n',\n",
       " '30',\n",
       " '%',\n",
       " '\\n',\n",
       " 'OFF',\n",
       " '\\n',\n",
       " '¥',\n",
       " '3',\n",
       " ',',\n",
       " '234',\n",
       " '(',\n",
       " '税込',\n",
       " ')～',\n",
       " '\\n',\n",
       " '通',\n",
       " ' ',\n",
       " '常',\n",
       " ' ',\n",
       " '価',\n",
       " ' ',\n",
       " '格',\n",
       " '  ',\n",
       " '¥',\n",
       " '4',\n",
       " ',',\n",
       " '620',\n",
       " '（',\n",
       " ' ',\n",
       " '税',\n",
       " ' ',\n",
       " '込',\n",
       " ' ',\n",
       " '）',\n",
       " ' ',\n",
       " '～',\n",
       " '\\n',\n",
       " 'セ',\n",
       " ' ',\n",
       " 'ラ',\n",
       " ' ',\n",
       " 'ブ',\n",
       " ' ',\n",
       " 'リ',\n",
       " ' ',\n",
       " 'ッ',\n",
       " ' ',\n",
       " 'ド',\n",
       " '\\n',\n",
       " 'フ',\n",
       " ' ',\n",
       " 'ラ',\n",
       " ' ',\n",
       " 'イ',\n",
       " ' ',\n",
       " 'パ',\n",
       " ' ',\n",
       " 'ン',\n",
       " ' ',\n",
       " '各',\n",
       " ' ',\n",
       " '種',\n",
       " '\\n',\n",
       " 'パ',\n",
       " ' ',\n",
       " 'ッ',\n",
       " ' ',\n",
       " 'ケ',\n",
       " ' ',\n",
       " 'ー',\n",
       " ' ',\n",
       " 'ジ',\n",
       " ' ',\n",
       " '切',\n",
       " ' ',\n",
       " '替',\n",
       " ' ',\n",
       " 'の',\n",
       " ' ',\n",
       " 'た',\n",
       " ' ',\n",
       " 'め',\n",
       " ' ',\n",
       " '特',\n",
       " ' ',\n",
       " '別',\n",
       " ' ',\n",
       " '価',\n",
       " ' ',\n",
       " '格',\n",
       " '\\n',\n",
       " '¥',\n",
       " '9',\n",
       " ',',\n",
       " '636',\n",
       " '(',\n",
       " '税込',\n",
       " ')～',\n",
       " '\\n',\n",
       " '通',\n",
       " ' ',\n",
       " '常',\n",
       " ' ',\n",
       " '価',\n",
       " ' ',\n",
       " '格',\n",
       " '  ',\n",
       " '¥',\n",
       " '16',\n",
       " ',',\n",
       " '060',\n",
       " '（',\n",
       " ' ',\n",
       " '税',\n",
       " ' ',\n",
       " '込',\n",
       " ' ',\n",
       " '）',\n",
       " ' ',\n",
       " '～',\n",
       " '\\n',\n",
       " '40',\n",
       " '%',\n",
       " '\\n',\n",
       " 'OFF',\n",
       " '\\n',\n",
       " '2',\n",
       " ' ',\n",
       " '本',\n",
       " ' ',\n",
       " 'セ',\n",
       " ' ',\n",
       " 'ッ',\n",
       " ' ',\n",
       " 'ト',\n",
       " ' ',\n",
       " '（',\n",
       " ' ',\n",
       " '1',\n",
       " ' ',\n",
       " '2',\n",
       " ' ',\n",
       " '.',\n",
       " ' ',\n",
       " '5',\n",
       " ' ',\n",
       " '/',\n",
       " ' ',\n",
       " '1',\n",
       " ' ',\n",
       " '4',\n",
       " ' ',\n",
       " 'c',\n",
       " ' ',\n",
       " 'm',\n",
       " ' ',\n",
       " '）',\n",
       " '\\n',\n",
       " '3',\n",
       " ' ',\n",
       " '本',\n",
       " ' ',\n",
       " 'セ',\n",
       " ' ',\n",
       " 'ッ',\n",
       " ' ',\n",
       " 'ト',\n",
       " ' ',\n",
       " '（',\n",
       " ' ',\n",
       " '1',\n",
       " ' ',\n",
       " '2',\n",
       " ' ',\n",
       " '.',\n",
       " ' ',\n",
       " '5',\n",
       " ' ',\n",
       " '/',\n",
       " ' ',\n",
       " '1',\n",
       " ' ',\n",
       " '4',\n",
       " ' ',\n",
       " '/',\n",
       " ' ',\n",
       " '1',\n",
       " ' ',\n",
       " '6',\n",
       " ' ',\n",
       " 'c',\n",
       " ' ',\n",
       " 'm',\n",
       " ' ',\n",
       " '）',\n",
       " '\\n',\n",
       " 'ココチカル',\n",
       " ' ',\n",
       " 'セラミック',\n",
       " 'ナイフ',\n",
       " '\\n',\n",
       " 'そ',\n",
       " ' ',\n",
       " 'の',\n",
       " ' ',\n",
       " '他',\n",
       " ' ',\n",
       " ',',\n",
       " ' ',\n",
       " '福',\n",
       " ' ',\n",
       " '袋',\n",
       " ' ',\n",
       " 'や',\n",
       " ' ',\n",
       " 'ボ',\n",
       " ' ',\n",
       " 'ト',\n",
       " ' ',\n",
       " 'ル',\n",
       " ' ',\n",
       " 'な',\n",
       " ' ',\n",
       " 'ど',\n",
       " ' ',\n",
       " 'セ',\n",
       " ' ',\n",
       " 'ー',\n",
       " ' ',\n",
       " 'ル',\n",
       " ' ',\n",
       " '品',\n",
       " ' ',\n",
       " 'を',\n",
       " ' ',\n",
       " '多',\n",
       " ' ',\n",
       " '数',\n",
       " ' ',\n",
       " 'ご',\n",
       " ' ',\n",
       " '用',\n",
       " ' ',\n",
       " '意',\n",
       " ' ',\n",
       " 'し',\n",
       " ' ',\n",
       " 'て',\n",
       " ' ',\n",
       " 'お',\n",
       " ' ',\n",
       " 'り',\n",
       " ' ',\n",
       " 'ま',\n",
       " ' ',\n",
       " 'す',\n",
       " ' ',\n",
       " '。',\n",
       " '\\n',\n",
       " '※',\n",
       " ' ',\n",
       " '在',\n",
       " ' ',\n",
       " '庫',\n",
       " ' ',\n",
       " '売',\n",
       " ' ',\n",
       " 'り',\n",
       " ' ',\n",
       " '切',\n",
       " ' ',\n",
       " 'り',\n",
       " ' ',\n",
       " '商',\n",
       " ' ',\n",
       " '品',\n",
       " ' ',\n",
       " 'も',\n",
       " ' ',\n",
       " 'ご',\n",
       " ' ',\n",
       " 'ざ',\n",
       " ' ',\n",
       " 'い',\n",
       " ' ',\n",
       " 'ま',\n",
       " ' ',\n",
       " 'す',\n",
       " ' ',\n",
       " '。',\n",
       " '\\n',\n",
       " '69',\n",
       " '%',\n",
       " '\\n',\n",
       " 'OFF',\n",
       " '\\n',\n",
       " 'MAX',\n",
       " '\\n',\n",
       " '※',\n",
       " 'ご',\n",
       " '購入',\n",
       " 'は',\n",
       " '京セラ',\n",
       " 'グループ',\n",
       " '社員',\n",
       " '限定',\n",
       " 'と',\n",
       " 'さ',\n",
       " 'せ',\n",
       " 'て',\n",
       " 'いただき',\n",
       " 'ます',\n",
       " 'ので',\n",
       " '、',\n",
       " '\\n',\n",
       " '\\u3000',\n",
       " '京セラ',\n",
       " 'グループ',\n",
       " '社員',\n",
       " '以外',\n",
       " 'へ',\n",
       " 'の',\n",
       " '情報',\n",
       " '共有',\n",
       " 'は',\n",
       " 'ご',\n",
       " '遠慮',\n",
       " 'ください',\n",
       " '。',\n",
       " '\\n',\n",
       " '※',\n",
       " '楽天',\n",
       " '市場',\n",
       " 'に',\n",
       " 'ない',\n",
       " '商品',\n",
       " 'も',\n",
       " 'クーポン',\n",
       " '使用',\n",
       " 'で',\n",
       " '30',\n",
       " '%',\n",
       " 'OFF',\n",
       " 'にて',\n",
       " 'お',\n",
       " '買い求め',\n",
       " 'い',\n",
       " 'た',\n",
       " 'だけ',\n",
       " 'ます',\n",
       " '。',\n",
       " '\\n',\n",
       " '京セラ',\n",
       " 'キッチン',\n",
       " '\\n',\n",
       " 'オンライン',\n",
       " 'ストア',\n",
       " '\\n',\n",
       " '全品',\n",
       " ' ',\n",
       " '30',\n",
       " '%',\n",
       " 'OFF',\n",
       " '\\n',\n",
       " 'I',\n",
       " ' ',\n",
       " 'D',\n",
       " '：',\n",
       " 'kyocera',\n",
       " '-',\n",
       " 'apd',\n",
       " '\\n',\n",
       " 'PW',\n",
       " '：',\n",
       " 'kyocera',\n",
       " '2312',\n",
       " '\\n',\n",
       " '京セラ',\n",
       " 'キッチン',\n",
       " '\\n',\n",
       " '楽天',\n",
       " '市場',\n",
       " '店',\n",
       " '\\n',\n",
       " 'クーポン',\n",
       " 'コード',\n",
       " '\\n',\n",
       " 'kyocera',\n",
       " '2312',\n",
       " '\\n',\n",
       " '京セラ',\n",
       " 'キッチン',\n",
       " '\\n',\n",
       " 'オンライン',\n",
       " 'ストア',\n",
       " '\\n',\n",
       " '同時',\n",
       " '開催',\n",
       " '\\n',\n",
       " '指',\n",
       " '\\n',\n",
       " 'を',\n",
       " '\\n',\n",
       " '汚',\n",
       " '\\n',\n",
       " 'さ',\n",
       " '\\n',\n",
       " 'ず',\n",
       " '\\n',\n",
       " '食',\n",
       " '\\n',\n",
       " 'べ',\n",
       " '\\n',\n",
       " 'ら',\n",
       " '\\n',\n",
       " 'れ',\n",
       " '\\n',\n",
       " 'る',\n",
       " '\\n',\n",
       " 'ポ',\n",
       " '\\n',\n",
       " 'テ',\n",
       " '\\n',\n",
       " 'ト',\n",
       " '\\n',\n",
       " 'チ',\n",
       " '\\n',\n",
       " 'ッ',\n",
       " '\\n',\n",
       " 'プ',\n",
       " '\\n',\n",
       " 'ス',\n",
       " '\\n',\n",
       " '専',\n",
       " '\\n',\n",
       " '用',\n",
       " '\\n',\n",
       " 'ト',\n",
       " '\\n',\n",
       " 'ン',\n",
       " '\\n',\n",
       " 'グ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from janome.tokenizer import Tokenizer\n",
    "import fitz\n",
    "\n",
    "def extract_text_from_directory(directory_path):\n",
    "    text = ''\n",
    "    tokenizer = Tokenizer()\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory_path, filename)\n",
    "            with fitz.open(pdf_path) as pdf_document:\n",
    "                for page_number in range(pdf_document.page_count):\n",
    "                    page = pdf_document[page_number]\n",
    "                    text += page.get_text(\"text\")  \n",
    "\n",
    "    # Tokenize Japanese text\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    separated_words = [token.surface for token in tokens]\n",
    "\n",
    "    return separated_words\n",
    "\n",
    "pdf_words = extract_text_from_directory(r'C:\\Users\\00220401626\\Desktop\\Words\\Muhim_Pdf')\n",
    "pdf_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15184e15-f9c4-44ad-998f-a3a6fa7aae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_insert_under += ' INSERT (' + ','.join([datarow for datarow in column_hist_latest]) + ')' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14360ff-d974-435e-a6fb-cb9abdde9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Work\\20_particle\\CSV\n",
    "\n",
    "{ \n",
    "  \"pc_csv\": \"\\\\10.143.64.59\\\\ParticleData\",\n",
    "  \"local_csv\": \"C:\\Work\\20_particle\\CSV\",\n",
    "  \"log_path\": \"C:\\Users\\00220401626\\Desktop\\test\\debug.log\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3a3e4b1-23ef-4291-937b-81847f408b41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file \"C:\\Users\\00220401626\\Desktop\\config.json\" created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"database\": \"AYB_APPL\",\n",
    "    \"host\": \"10.143.16.244\",\n",
    "    \"port\": \"50000\",\n",
    "    \"protocol\":\"TCPIP\",\n",
    "    \"uid\":\"IOT_DATA\",\n",
    "    \"pwd\":\"asd23fgh\",\n",
    "    \"pc_csv\": \"\\\\10.143.64.59\\\\ParticleData\",\n",
    "    \"local_csv\": \"C:\\\\Work\\\\20_particle\\\\CSV\",\n",
    "    \"log\": \"C:\\\\Work\\\\20_particle\\\\debug.log\",\n",
    "    \"insertion_time\":\" \"\n",
    "}\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\config.json'\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f'JSON file \"{file_path}\" created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2eb277-d62d-4b79-9759-4dba0c78b90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file \"C:\\Users\\00220401626\\Desktop\\config.json\" created successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    \"database\": \"AYB_APPL\",\n",
    "    \"host\": \"10.143.16.244\",\n",
    "    \"port\": \"50000\",\n",
    "    \"protocol\": \"TCPIP\",\n",
    "    \"uid\": \"IOT_DATA\",\n",
    "    \"pwd\": \"asd23fgh\",\n",
    "    \"pc_csv\": \"C:\\\\Users\\\\00220401626\\\\Desktop\\\\Ayabe\\\\FMS\\\\CsvData\\\\2023\",\n",
    "    \"local_csv\": \"C:\\\\Users\\\\00220401626\\\\Desktop\\test\\\\CSV\",\n",
    "    \"log\": \"C:\\\\Users\\\\00220401626\\\\Desktop\\test\\\\debug.log\",\n",
    "    \"insertion_time\": \"2023/01/01 10:00:00\"\n",
    "}\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\00220401626\\\\Desktop\\\\config.json'\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(data, json_file, indent=2)\n",
    "\n",
    "print(f'JSON file \"{file_path}\" created successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398ca9f-1c8b-43ee-86fa-9649552351ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
