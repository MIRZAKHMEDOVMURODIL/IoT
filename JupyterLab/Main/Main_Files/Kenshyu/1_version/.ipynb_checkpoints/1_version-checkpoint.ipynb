{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4601729a-06ff-4c19-bdfe-01b88d97ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import mojimoji\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47aba8e-a3f4-41c4-9bd2-06e08f8d580f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# lotlist_origin作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badb2c06-b38b-498d-af02-18f7f3ee4c7e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step_1~4 eqdataの読み込み・加工"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad8a21-0970-4422-9caf-ce426e3c0bd1",
   "metadata": {},
   "source": [
    "## Step_1 eqdataの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b3e21e-4df6-490a-acdb-8166cb09da3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\neqdataの更新時間からデータの取得時間を算出する\\n笹倉さんから頂いたプログラム\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "eqdataの更新時間からデータの取得時間を算出する\n",
    "笹倉さんから頂いたプログラム\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b248e6e0-61f0-44bf-82e8-b7bfb77c3dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(input_dir,output_dir,st_time,ed_time):\n",
    "    \n",
    "    files = glob.glob(input_dir)\n",
    "    print(str(len(files))+\"files\")\n",
    "    print(\"step_1 is started\")  \n",
    "    for file,i in zip(files,range(len(files))):\n",
    "        out_file = output_dir+str(str(i).zfill(5))+\".csv\"\n",
    "        t = os.path.getmtime(file)\n",
    "        d = datetime.datetime.fromtimestamp(t)\n",
    "        if (np.datetime64(d)>=st_time) and (np.datetime64(d)<=ed_time):\n",
    "            df = pd.read_csv(file,header=[2,3],index_col=0)\n",
    "            df.insert(loc = 0, column= \"file_end_time\", value= str(d))\n",
    "            df.columns = [\"file_end_time\",\"Time_msec\",\"X_POS_mm\",\"Z_POS_mm\",\"X_TCMD_%\",\"Z_TCMD_%\",\"B_TCMD_%\",\"C_TCMD_%\",\"S_TCMD_%\",\"S_SPEED_rpm\"]\n",
    "            df.insert(loc = 0, column= \"file_start_time\", value= str(d-(pd.to_timedelta(df[\"Time_msec\"].astype(int).max(),\"S\"))/1000))\n",
    "            df=df[df[\"S_SPEED_rpm\"]>=3490.0]\n",
    "            df.to_csv(out_file, header=True, index=False, encoding=\"cp932\")\n",
    "        else:\n",
    "            continue\n",
    "    print(\"step_1 is finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfa6de-2a2c-4609-ab53-e06f3d2ad1a2",
   "metadata": {},
   "source": [
    "## Step_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab49478-8b08-4adb-b123-611c95ae9b47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def merge_csv_files(output_dir):   \n",
    "    \n",
    "    print(\"step_2 is started\")\n",
    "    files = glob.glob(output_dir+\"*.csv\")\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        i = pd.read_csv(file,encoding=\"cp932\")\n",
    "        dfs.append(i)\n",
    "    df = pd.concat(dfs, axis=0)\n",
    "    print(\"step_2 is finished\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96826433-51c5-448a-9bc1-5688210c6428",
   "metadata": {},
   "source": [
    "## Step_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8244ba7-aece-4b7e-9cb9-a1d6fa3208e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df_servo):\n",
    "    \n",
    "    print(\"step_3 is started\")\n",
    "    df_servo[\"DATETIME\"] = pd.to_datetime(df_servo[\"file_start_time\"]) + pd.to_timedelta(df_servo[\"Time_msec\"]/1000, \"S\")\n",
    "    df_servo = df_servo.sort_values([\"DATETIME\"])\n",
    "    \n",
    "    count = 0\n",
    "    uid = 0\n",
    "    time_list = df_servo[\"DATETIME\"]\n",
    "    uid_list = []\n",
    "    th_time = np.timedelta64(60, 's')\n",
    "\n",
    "    for i in time_list:\n",
    "        if count == 0:\n",
    "            uid_list.append(uid)\n",
    "            count += 1\n",
    "            j = i\n",
    "        else:\n",
    "            if i > j + th_time:\n",
    "                uid += 1\n",
    "                uid_list.append(uid)\n",
    "                j = i\n",
    "            else:\n",
    "                uid_list.append(uid)\n",
    "                j = i\n",
    "\n",
    "    df_servo[\"uid\"] = uid_list\n",
    "    \n",
    "    print(\"step_3 is finished\")\n",
    "\n",
    "    return df_servo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b68574-6531-481a-807d-ad9e8c3395a6",
   "metadata": {},
   "source": [
    "## Step_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa28f3f9-bb2b-4a38-b010-2fcddeeebfb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_df_flag(df_servo):  \n",
    "    \n",
    "    print(\"step_4 is started\")\n",
    "    df_uid = df_servo.loc[:,[\"uid\",\"DATETIME\"]].drop_duplicates(subset = \"uid\")\n",
    "    df_std = df_servo.groupby(\"uid\").std(numeric_only=True)\n",
    "    df_std.reset_index(inplace=True)\n",
    "    df_etd = df_servo.groupby(\"uid\").max()\n",
    "    df_etd.reset_index(inplace=True)\n",
    "    endtime = df_etd.loc[:,[\"uid\",\"DATETIME\"]]\n",
    "    endtime = endtime.rename(columns={\"DATETIME\": \"DATETIME_e\"})\n",
    "    df_std[\"FLAG\"] = 0\n",
    "    df_std.loc[df_std[\"B_TCMD_%\"] <= 0.2, \"FLAG\"] = 1\n",
    "    df_flag = df_uid.merge(df_std.loc[:,[\"uid\",\"FLAG\"]],how=\"inner\",on=\"uid\")\n",
    "    df_flag = endtime.merge(df_flag.loc[:,[\"uid\",\"DATETIME\",\"FLAG\"]],how=\"inner\",on=\"uid\")\n",
    "    df_flag = df_flag.reindex(columns=['uid', 'DATETIME', 'DATETIME_e','FLAG'])\n",
    "    df_flag = df_flag.rename(columns={'DATETIME':'DATETIME_S','DATETIME_e':'DATETIME_E'})\n",
    "    print(\"step_4 is finished\")\n",
    "\n",
    "    return df_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f29bb-21da-4a37-8987-35b88887a337",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step_5 ドレッシング記録の読み込み・加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "506906a6-5a27-48cc-adad-bfcd2b0dfca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_lots(df_flag, df_dress_path): \n",
    "    \n",
    "    print(\"step_5 is started\")\n",
    "    df_dress = pd.read_excel(df_dress_path, skiprows=1)\n",
    "    df_dress = df_dress.loc[:,['s1_作業指図書no','s1_数量','s1_ドレスサイクルs', 's1_ドレスサイクルe','s1_開始dt', 's1_終了dt']]\n",
    "    df_dress = df_dress.dropna(subset=['s1_開始dt'])\n",
    "    df_dress[\"s1_開始dt\"] = pd.to_datetime(df_dress[\"s1_開始dt\"])\n",
    "    df_dress[\"s1_終了dt\"] = pd.to_datetime(df_dress[\"s1_終了dt\"], errors='ignore')\n",
    "    df_flag[\"lotno\"] = \"0000000-000\"\n",
    "\n",
    "    for k in range(len(df_flag)):\n",
    "        for i in range(len(df_dress)):\n",
    "            fdt = np.datetime64(str(df_flag[\"DATETIME_S\"][k]))\n",
    "            sdt = np.datetime64(str(df_dress[\"s1_開始dt\"][i]))\n",
    "            edt = np.datetime64(str(df_dress[\"s1_終了dt\"][i]))\n",
    "            if (fdt >= sdt ) and (fdt <= edt ) :\n",
    "                df_flag.loc[k, \"lotno\"] = df_dress.loc[i, \"s1_作業指図書no\"]\n",
    "            elif (sdt > fdt ):\n",
    "                break\n",
    "    df_flag[\"lotno\"] = df_flag[\"lotno\"].apply(lambda x: mojimoji.zen_to_han(x) )\n",
    "    print(\"step_5 is finished\")\n",
    "    \n",
    "    return df_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5115f-a142-4102-9f0f-b31abd3e2b2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step_6 focasdata読み込み・加工"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51107c03-f026-4780-884f-d32661d29b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_data_1(focas_dir, df_flag):\n",
    "    \n",
    "    print(\"step_6 is started\")\n",
    "    df_focas = pd.read_csv(focas_dir,sep=\"\\t\")\n",
    "    df_focas['DATETIME'] = pd.to_datetime(df_focas['DATETIME'])\n",
    "    df_flag[\"DATETIME_S\"] = df_flag['DATETIME_S'].dt.round(\"s\")\n",
    "    df_flag[\"DATETIME_E\"] = df_flag['DATETIME_E'].dt.round(\"s\")\n",
    "    df_focas['DATETIME_S'] = df_focas['DATETIME'].dt.round(\"s\")\n",
    "    df_focas.drop_duplicates(subset=[\"DATETIME\"],keep='last',inplace=True)\n",
    "    df_focas.pop('DATETIME')\n",
    "\n",
    "    pu_cols = ['DATETIME_S','2:var818','2:x_axis', '2:z_axis', '2:c_axis']\n",
    "    df_flag = df_flag.merge(df_focas.loc[:,pu_cols],left_on=[\"DATETIME_S\"],right_on=[\"DATETIME_S\"],how=\"inner\")\n",
    "    df_flag = df_flag.loc[:,[\"uid\",\"FLAG\",\"lotno\",\"DATETIME_S\",\"DATETIME_E\",'2:var818','2:x_axis', '2:z_axis', '2:c_axis']]\n",
    "    df_flag = df_flag.drop_duplicates(subset=['DATETIME_S', 'DATETIME_E'])\n",
    "    print(\"step_6 is finished\")\n",
    "    \n",
    "    return df_flag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0a5b66-1809-452c-9f23-a5c79ae95efe",
   "metadata": {},
   "source": [
    "# Main_File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a904f14-006f-40b3-9fbe-218f2a52b84b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280files\n",
      "step_1 is started\n",
      "step_1 is finished\n",
      "step_2 is started\n",
      "step_2 is finished\n",
      "step_3 is started\n",
      "step_3 is finished\n",
      "step_4 is started\n",
      "step_4 is finished\n",
      "step_5 is started\n",
      "step_5 is finished\n",
      "step_6 is started\n",
      "step_6 is finished\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    ##製品の加工時期（範囲の入っていればよいです）\n",
    "    start_time = \"2023-02-07\"\n",
    "    end_time = \"2023-02-09\"\n",
    "    st_time = np.datetime64(str(start_time))\n",
    "    ed_time = np.datetime64(str(end_time))\n",
    "    \n",
    "    ##inputディレクトリー\n",
    "    ##eqdataのディレクトリー\n",
    "    input_dir = r\"C:\\Users\\YAMAJI\\Downloads\\2300002-000_ver2\\2300002-000\\*.csv\"\n",
    "    ##フォーカスデータのディレクトリー\n",
    "    focas_dir = r\"C:\\Users\\YAMAJI\\Downloads\\1675728784.2723718.tsv\" \n",
    "    ##ドレッシング記録のディレクトリー\n",
    "    dre_dir = r\"C:\\Users\\YAMAJI\\OneDrive\\新入社員研修\\メディカル\\05_グライディングセンタ\\ドレッシング記録20230216.xlsx\"\n",
    "    \n",
    "    ##outputディレクトリー\n",
    "    output_dir = r\"C:\\Users\\YAMAJI\\Desktop\\output\\新しいフォルダー\"\n",
    "\n",
    "    \n",
    "    read_csv(input_dir, output_dir, st_time, ed_time)       #step1　eqdataの読み込み・加工\n",
    "    df=merge_csv_files(output_dir)                          #step2\n",
    "    df_servo1=preprocess_data(df)                           #step3\n",
    "    df_flag = create_df_flag(df_servo1)                     #step4\n",
    "    df1 = flag_lots(df_flag, dre_dir)                       #step5 ドレッシング記録を読み込んでdf_flagと結合\n",
    "    df2 = process_data_1(focas_dir,df1)                     #step6 focasdataを読み込んでdf1と結合\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4447def6-020e-4862-b7cc-08b6f77f9d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>FLAG</th>\n",
       "      <th>lotno</th>\n",
       "      <th>DATETIME_S</th>\n",
       "      <th>DATETIME_E</th>\n",
       "      <th>2:var818</th>\n",
       "      <th>2:x_axis</th>\n",
       "      <th>2:z_axis</th>\n",
       "      <th>2:c_axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-07 10:24:57</td>\n",
       "      <td>2023-02-07 10:32:37</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-219.386307</td>\n",
       "      <td>-94.583504</td>\n",
       "      <td>358.581787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-07 10:36:38</td>\n",
       "      <td>2023-02-07 10:44:14</td>\n",
       "      <td>0.18</td>\n",
       "      <td>-219.406296</td>\n",
       "      <td>-104.206596</td>\n",
       "      <td>316.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-07 10:50:26</td>\n",
       "      <td>2023-02-07 10:58:07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-219.411301</td>\n",
       "      <td>-99.313301</td>\n",
       "      <td>226.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-07 12:15:42</td>\n",
       "      <td>2023-02-07 12:23:25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-219.410797</td>\n",
       "      <td>-96.764999</td>\n",
       "      <td>22.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-07 12:15:42</td>\n",
       "      <td>2023-02-07 12:23:25</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-219.410797</td>\n",
       "      <td>-98.151604</td>\n",
       "      <td>195.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-08 08:40:57</td>\n",
       "      <td>2023-02-08 08:48:34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-219.468597</td>\n",
       "      <td>-104.489403</td>\n",
       "      <td>198.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-08 09:11:27</td>\n",
       "      <td>2023-02-08 09:19:09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-219.468704</td>\n",
       "      <td>-96.488602</td>\n",
       "      <td>165.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-08 09:40:01</td>\n",
       "      <td>2023-02-08 09:47:46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-219.468796</td>\n",
       "      <td>-94.596397</td>\n",
       "      <td>335.763000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-08 09:56:56</td>\n",
       "      <td>2023-02-08 09:57:38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-219.468597</td>\n",
       "      <td>-98.690300</td>\n",
       "      <td>252.899994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2300002-000</td>\n",
       "      <td>2023-02-08 09:56:56</td>\n",
       "      <td>2023-02-08 09:57:38</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-219.468597</td>\n",
       "      <td>-100.130302</td>\n",
       "      <td>65.699997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    uid  FLAG        lotno          DATETIME_S          DATETIME_E  2:var818  \\\n",
       "0     0     0  2300002-000 2023-02-07 10:24:57 2023-02-07 10:32:37      0.14   \n",
       "1     1     0  2300002-000 2023-02-07 10:36:38 2023-02-07 10:44:14      0.18   \n",
       "2     2     0  2300002-000 2023-02-07 10:50:26 2023-02-07 10:58:07      0.19   \n",
       "3     3     0  2300002-000 2023-02-07 12:15:42 2023-02-07 12:23:25      0.19   \n",
       "4     3     0  2300002-000 2023-02-07 12:15:42 2023-02-07 12:23:25      0.19   \n",
       "..  ...   ...          ...                 ...                 ...       ...   \n",
       "59   53     0  2300002-000 2023-02-08 08:40:57 2023-02-08 08:48:34      0.20   \n",
       "60   54     0  2300002-000 2023-02-08 09:11:27 2023-02-08 09:19:09      0.20   \n",
       "61   55     0  2300002-000 2023-02-08 09:40:01 2023-02-08 09:47:46      0.20   \n",
       "62   56     1  2300002-000 2023-02-08 09:56:56 2023-02-08 09:57:38      0.20   \n",
       "63   56     1  2300002-000 2023-02-08 09:56:56 2023-02-08 09:57:38      0.20   \n",
       "\n",
       "      2:x_axis    2:z_axis    2:c_axis  \n",
       "0  -219.386307  -94.583504  358.581787  \n",
       "1  -219.406296 -104.206596  316.500000  \n",
       "2  -219.411301  -99.313301  226.500000  \n",
       "3  -219.410797  -96.764999   22.500000  \n",
       "4  -219.410797  -98.151604  195.300003  \n",
       "..         ...         ...         ...  \n",
       "59 -219.468597 -104.489403  198.899994  \n",
       "60 -219.468704  -96.488602  165.300003  \n",
       "61 -219.468796  -94.596397  335.763000  \n",
       "62 -219.468597  -98.690300  252.899994  \n",
       "63 -219.468597 -100.130302   65.699997  \n",
       "\n",
       "[64 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa2b6f-2094-412d-8dc2-9e5605989510",
   "metadata": {},
   "source": [
    "# CSV出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df35e91-191b-414c-bf91-88221a7413a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (541474172.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    df2.to_csv(\"C:\\Users\\YAMAJI\\Desktop\\output\\1\\lotlist_origin.csv\",index=False,encoding=\"cp932\")\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# df2.to_csv(r\"C:\\Users\\YAMAJI\\Desktop\\output\\1\\lotlist_origin.csv\",index=False,encoding=\"cp932\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
