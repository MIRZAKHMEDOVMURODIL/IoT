{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import datetime as dt \n",
    "from os.path import join\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import ibm_db\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "json_path = r'C:\\Users\\00220401626\\Desktop\\teams\\config.json'\n",
    "teams_webhook_url = \"https://kyoceragp.webhook.office.com/webhookb2/32c8e9d8-fee1-47b5-8f88-7c024b169401@82cc187e-25d5-45e4-8c34-8434bf6075fe/IncomingWebhook/c008d92acff64b93a35fa912edecdbf3/329f5970-aad5-4b39-90b5-cf6569c670e1\"             \n",
    "\n",
    "try:\n",
    "    with open(json_path) as json_file:\n",
    "        config = json.load(json_file)\n",
    "\n",
    "    # Extract Configuration values\n",
    "    database_1 = config['database_1']\n",
    "    host_1 = config['host_1']\n",
    "    port_1 = config['port_1']\n",
    "    protocol_1 = config['protocol_1']\n",
    "    user_1 = config['user_1']\n",
    "    password_1 = config['password_1']\n",
    "    \n",
    "    database_2 = config['database_2']\n",
    "    host_2 = config['host_2']\n",
    "    port_2 = config['port_2']\n",
    "    protocol_2 = config['protocol_2']\n",
    "    user_2 = config['user_2']\n",
    "    password_2 = config['password_2']\n",
    "\n",
    "    log = config['log']  \n",
    "    days = int(config['days'])\n",
    "    insertion_time = str(config['insertion_time'])\n",
    "    inserted_time = dt.datetime.strptime(insertion_time, '%Y-%m-%d %H:%M:%S')\n",
    "    inserted_day = inserted_time.strftime('%Y%m%d')\n",
    "\n",
    "    # Logging Settings    \n",
    "    if not os.path.exists(log):\n",
    "        os.makedirs(log, exist_ok=True)\n",
    "        \n",
    "    dt_st = datetime.now()\n",
    "    log_path = join(log, f\"debug_{dt_st.strftime('%Y%m%d')}.log\")\n",
    "    log_formatter = logging.Formatter('%(asctime)s [%(levelname)s]: %(message)s', datefmt='%Y-%m-%d %H:%M:%S')\n",
    "    log_handler = RotatingFileHandler(filename=log_path, maxBytes=1048576, backupCount=10, delay=True)\n",
    "    log_handler.setFormatter(log_formatter)\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.addHandler(log_handler)\n",
    "\n",
    "    logging.info(\"Step_1: Extract JSON Configuration Values\")\n",
    "    print(\"Step_1: Extract JSON Configuration Values\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"Step_1: An error occurred while loading configuration: {e}\")\n",
    "    print(f\"Step_1: An error occurred while loading configuration: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "def take_data_from_database():\n",
    "    try:\n",
    "        conn = psycopg2.connect(database=database_1, user=user_1, password=password_1, host=host_1, port=port_1)\n",
    "\n",
    "        sql_query = \"\"\"\n",
    "            SELECT *\n",
    "            FROM mm_01 \n",
    "            WHERE state IN (2, 3) AND timedate > %s\n",
    "            UNION ALL\n",
    "            SELECT *\n",
    "            FROM mm_02 \n",
    "            WHERE state IN (2, 3) AND timedate > %s;\n",
    "        \"\"\"\n",
    "        \n",
    "        # Execute SQL query with parameters\n",
    "        df = pd.read_sql_query(sql_query, conn, params=(inserted_time, inserted_time))\n",
    "\n",
    "        # Close the database connection\n",
    "        conn.close()\n",
    "\n",
    "        # Log and return the DataFrame\n",
    "        logging.info(\"Step_2: Successfully fetched data from the database\")\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log and print any errors\n",
    "        logging.error(f\"Step_2: Error while connecting to PostgreSQL: {e}\")\n",
    "        print(f\"Step_2: Error while connecting to PostgreSQL: {e}\")\n",
    "\n",
    "df = take_data_from_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "def take_data_from_database():  \n",
    "    try:\n",
    "        conn = psycopg2.connect(database=database_1, user=user_1, password=password_1, host=host_1, port=port_1)\n",
    "        sql_query = \"\"\"\n",
    "                    SELECT *\n",
    "                    FROM mm_01\n",
    "                    WHERE state IN (2, 3) AND timedate > %s;\n",
    "                \"\"\"\n",
    "        \n",
    "        df = pd.read_sql_query(sql_query, conn, params=(inserted_time,))\n",
    "\n",
    "        logging.info(\"Step_2: Extract JSON Configuration Values\")\n",
    "        print(\"Step_2: Extract JSON Configuration Values\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Step_2: Error while connecting to PostgreSQL: {e}\")\n",
    "        print(f\"Step_2: Error while connecting to PostgreSQL: {e}\")\n",
    "        \n",
    "df=take_data_from_database()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 \n",
    "def insert_into_database(df):\n",
    "    try:\n",
    "        dsn = f\"DATABASE={database_2};HOSTNAME={host_2};PORT={port_2};PROTOCOL={protocol_2};UID={user_2};PWD={password_2}\"\n",
    "        conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "        if conn:\n",
    "            logging.info(\"Step_3: 1.Connected to Database\")\n",
    "            print(\"Step_3: 1.Connected to Database\")\n",
    "    except Exception as e:\n",
    "        print(\"Step_3: 1.Failed to Connect to Database:\", e)\n",
    "        logging.error(\"Step_3: 1.Failed to Connect to Database:\", e)\n",
    "\n",
    "\n",
    "    values = ''\n",
    "    for index, row in df.iterrows():\n",
    "        value_1 = 'Particles'\n",
    "        value_2 = 'MM_01'\n",
    "        value_3 = row['timedate']\n",
    "        value_4 = row['state']\n",
    "        value_5 = '0.5, 1.0, 5.0, 10.0'\n",
    "        value_6 = f\"{row['0.5']}, {row['1.0']}, {row['5.0']}, {row['10.0']}\"\n",
    "\n",
    "        values += f\"('{value_1}','{value_2}', '{value_3}', '{value_4}', '{value_5}', '{value_6}'),\"\n",
    "        \n",
    "    values = values[:-1] \n",
    "\n",
    "    insert_query = f\"INSERT INTO IOT_DATA.THRESHOLD_ALERT(CATEGORY, EQP, TS_DT, STATE, DATA_COLUMN, DATA_VALUE) VALUES {values};\"\n",
    "    stmt = ibm_db.prepare(conn, insert_query)\n",
    "\n",
    "    try:\n",
    "        if ibm_db.execute(stmt):\n",
    "            logging.info(\"Step_3: 2.Inserted to Database\")\n",
    "            print(\"Step_3: 2.Inserted to Database\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Step_3: 2.Error: {e}\")\n",
    "        print(f\"Step_3: 2.Error: {e}\")\n",
    "\n",
    "insert_into_database(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "def send_teams_message(df):\n",
    "    message_text = \"\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        TITLE = row['timedate']\n",
    "        value_1 = row['state']  \n",
    "        value_2 = 'MM_01'  \n",
    "        value_3 = row['0.5']  \n",
    "        value_4 = row['1.0'] \n",
    "        value_5 = row['5.0']  \n",
    "        value_6 = row['10.0'] \n",
    "        link = \"http://mb.in.kyocera.co.jp/motionboard/main?mbid=fid5uk\"\n",
    "\n",
    "        message_text += f\"超過アラート{TITLE}\\n\\n判定: {value_1}\\n\\n種別: {value_2}\\n\\n装置: {value_3}\\n\\n対象データ名: {value_4}\\n\\nデータ値: {value_5}\\n\\nしきい値: {value_6}\\n\\n↓MotionBoardへのリンク\\n\\n{link}\\n\\n----------------------------\\n\\n\"\n",
    "\n",
    "    payload = {\"text\": message_text}\n",
    "\n",
    "    response = requests.post(teams_webhook_url, data=json.dumps(payload), verify=False)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        logging.info(\"Step_4: Message sent successfully to Microsoft Teams\")\n",
    "        print(\"Step_4: Message sent successfully to Microsoft Teams\")      \n",
    "    else:\n",
    "        logging.info(f\"Step_4: Failed to send message. Status code: {response.status_code}, Response: {response.text}\")\n",
    "        print(f\"Step_4: Failed to send message. Status code: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "send_teams_message(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 \n",
    "def update_json(df):\n",
    "    config['insertion_time'] = str(df['timedate'].max())\n",
    "    time=config['insertion_time']\n",
    "    json_data = json.dumps(config, indent=2)\n",
    "\n",
    "    with open(json_path, 'w') as output_file:\n",
    "        output_file.write(json_data)\n",
    "\n",
    "    logging.info(f\"Step_5: Insertion Time is Updated: {time}\")\n",
    "    print(f\"Step_5: Insertion Time is Updated {time}\") \n",
    "\n",
    "update_json(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = take_data_from_database() \n",
    "insert_into_database(df)\n",
    "send_teams_message(df)\n",
    "update_json(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下記はテスト用のコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending messages using for loop : OK\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Column_1': ['Title 1', 'Title 2', 'Title 3', 'Title 4', 'Title 5', 'Title 6', 'Title 7', 'Title 8', 'Title 9', 'Title 10'],\n",
    "    'Column_2': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Column_3': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'Column_4': [21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
    "    'Column_5': [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    'Column_6': [41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n",
    "    'Column_7': [51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "def send_teams_message_1(df):\n",
    "    teams_webhook_url = \"https://kyoceragp.webhook.office.com/webhookb2/32c8e9d8-fee1-47b5-8f88-7c024b169401@82cc187e-25d5-45e4-8c34-8434bf6075fe/IncomingWebhook/c008d92acff64b93a35fa912edecdbf3/329f5970-aad5-4b39-90b5-cf6569c670e1\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        TITLE = row['Column_1']\n",
    "        value_1 = row['Column_2']  \n",
    "        value_2 = row['Column_3']  \n",
    "        value_3 = row['Column_4']  \n",
    "        value_4 = row['Column_5'] \n",
    "        value_5 = row['Column_6']  \n",
    "        value_6 = row['Column_7'] \n",
    "        link = \"http://mb.in.kyocera.co.jp/motionboard/main?mbid=fid5uk\"\n",
    "\n",
    "        message = f\"{TITLE}\\n\\n判定: {value_1}\\n\\n種別: {value_2}\\n\\n装置: {value_3}\\n\\n対象データ名: {value_4}\\n\\nデータ値: {value_5}\\n\\nしきい値: {value_6}\\n\\n↓MotionBoardへのリンク\\n{link}\\n\\n\"\n",
    "\n",
    "        payload = {\"text\": message}\n",
    "\n",
    "        response = requests.post(teams_webhook_url, data=json.dumps(payload), verify=False)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(\"Message sent successfully to Microsoft Teams!\")\n",
    "        else:\n",
    "            print(f\"Failed to send message. Status code: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "send_teams_message(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send all rows in one excute  : OK\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Column_1': ['Title 1', 'Title 2', 'Title 3', 'Title 4', 'Title 5', 'Title 6', 'Title 7', 'Title 8', 'Title 9', 'Title 10'],\n",
    "    'Column_2': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Column_3': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'Column_4': [21, 22, 23, 24, 25, 26, 27, 28, 29, 30],\n",
    "    'Column_5': [31, 32, 33, 34, 35, 36, 37, 38, 39, 40],\n",
    "    'Column_6': [41, 42, 43, 44, 45, 46, 47, 48, 49, 50],\n",
    "    'Column_7': [51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "teams_webhook_url = \"https://kyoceragp.webhook.office.com/webhookb2/32c8e9d8-fee1-47b5-8f88-7c024b169401@82cc187e-25d5-45e4-8c34-8434bf6075fe/IncomingWebhook/c008d92acff64b93a35fa912edecdbf3/329f5970-aad5-4b39-90b5-cf6569c670e1\"             \n",
    "\n",
    "def send_teams_message_2(df):\n",
    "    message_text = \"\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        TITLE = row['Column_1']\n",
    "        value_1 = row['Column_2']  \n",
    "        value_2 = row['Column_3']  \n",
    "        value_3 = row['Column_4']  \n",
    "        value_4 = row['Column_5'] \n",
    "        value_5 = row['Column_6']  \n",
    "        value_6 = row['Column_7'] \n",
    "        link = \"http://mb.in.kyocera.co.jp/motionboard/main?mbid=fid5uk\"\n",
    "\n",
    "        message_text += f\"{TITLE}\\n\\n判定: {value_1}\\n\\n種別: {value_2}\\n\\n装置: {value_3}\\n\\n対象データ名: {value_4}\\n\\nデータ値: {value_5}\\n\\nしきい値: {value_6}\\n\\n↓MotionBoardへのリンク\\n\\n{link}\\n\\n----------------------------\\n\\n\"\n",
    "\n",
    "    payload = {\"text\": message_text}\n",
    "\n",
    "    response = requests.post(teams_webhook_url, data=json.dumps(payload), verify=False)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        print(\"Message sent successfully to Microsoft Teams!\")\n",
    "    else:\n",
    "        print(f\"Failed to send message. Status code: {response.status_code}, Response: {response.text}\")\n",
    "\n",
    "send_teams_message_2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "\n",
    "dsn = f\"DATABASE={database_2};HOSTNAME={host_2};PORT={port_2};PROTOCOL={protocol_2};UID={user_2};PWD={password_2}\"\n",
    "conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "delete_query = \"DELETE FROM THRESHOLD_ALERT\"\n",
    "\n",
    "try:\n",
    "    ibm_db.autocommit(conn, ibm_db.SQL_AUTOCOMMIT_OFF)\n",
    "    if ibm_db.exec_immediate(conn, delete_query):\n",
    "        print(\"Existing data deleted successfully\")\n",
    "\n",
    "    ibm_db.commit(conn)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "    ibm_db.rollback(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "def take_data_from_database():  \n",
    "    try:\n",
    "        logging.info(\"Step_2: Data is taken from the Database.\")\n",
    "        print(\"Step_2: Data is taken from the Database.\")\n",
    "\n",
    "        table = ['mm_01', 'mm_02', 'mm_03', 'mm_04']\n",
    "        conn = psycopg2.connect(database=database_1, user=user_1, password=password_1, host=host_1, port=port_1)\n",
    "        for table_name in table:\n",
    "            sql_query = \"\"\"\n",
    "                        SELECT *\n",
    "                        FROM %s\n",
    "                        WHERE state IN (2, 3) AND timedate > %s;\n",
    "                    \"\"\"\n",
    "            \n",
    "            df = pd.read_sql_query(sql_query, conn, params=(table_name, inserted_time,)) \n",
    "            df['state'] = df['state'].replace({2: '警報', 3: '警告'})\n",
    "      \n",
    "            message_text = \"\"\n",
    "            if df:\n",
    "                for index, row in df.iterrows():\n",
    "                    value_0 = row['timedate']\n",
    "                    value_1 = row['state']  \n",
    "                    value_2 = '気中パーティクル'\n",
    "                    value_3 = table_name \n",
    "\n",
    "                    value_4 = row['0.5']\n",
    "                    value_5 = row['1.0']  \n",
    "                    value_6 = row['5.0'] \n",
    "                    value_7 = row['10.0']\n",
    "                    \n",
    "                    link = \"http://mb.in.kyocera.co.jp/motionboard/main?mbid=fidkma77jxaifa65c65aaahv5mwqy\"\n",
    "                    message_text += f\"超過アラート   : {value_0}\\n\\n判定: {value_1}\\n\\n種別: {value_2}\\n\\n装置: {value_3}\\n\\nデータ:\\n\\n\\t 0.5  = {value_4}\\n\\t 1.0  = {value_5}\\n\\t 5.0  = {value_6}\\n\\t 10.0 = {value_7}\\nしきい値: \\n\\n↓MotionBoardへのリンク\\n\\n{link}\\n\\n----------------------------\\n\\n\"\n",
    "        \n",
    "                \n",
    "                    payload = {\"text\": message_text}\n",
    "                    response = requests.post(teams_webhook_url, data=json.dumps(payload), verify=False)\n",
    "                \n",
    "                    if response.status_code == 200:\n",
    "                        logging.info(\"Step_3: Message sent successfully to Microsoft Teams\")\n",
    "                        print(\"Step_3: Message sent successfully to Microsoft Teams\")      \n",
    "                    else:\n",
    "                        logging.info(f\"Step_3: Failed to send message. Status code: {response.status_code}, Response: {response.text}\")\n",
    "                        print(f\"Step_3: Failed to send message. Status code: {response.status_code}, Response: {response.text}\")\n",
    "                        return df\n",
    "            else:\n",
    "                logging.info(f\"There is no state 2 or 3 data in {table_name}\")\n",
    "                print(f\"There is no state 2 or 3 data in {table_name}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Step_2: Error while connecting to PostgreSQL: {e}\")\n",
    "        print(f\"Step_2: Error while connecting to PostgreSQL: {e}\")\n",
    "        \n",
    "            \n",
    "send_teams_message(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "${CATEGORY} \n",
    "${EQP} \n",
    "${TS_DT}\n",
    "${DATA_COLUMN} \n",
    "${INPUT_DT}\n",
    "${INPUT_PERSON} \n",
    "${INPUT_COMMENT} \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from datetime import datetime\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "log = \"logs\"\n",
    "os.makedirs(log, exist_ok=True)\n",
    "\n",
    "log_path = join(log,\"debug.log\")\n",
    "log_formatter = logging.Formatter('%(asctime)s [%(levelname)s]: %(message)s')\n",
    "log_handler = RotatingFileHandler(filename=log_path, maxBytes=1048576, backupCount=10, delay=True)\n",
    "log_handler.setFormatter(log_formatter)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)  \n",
    "logger.addHandler(log_handler)\n",
    "\n",
    "\n",
    "a0 = sys.argv[0]\n",
    "a1 = sys.argv[1]\n",
    "a2 = sys.argv[2]\n",
    "a3 = sys.argv[3]\n",
    "a4 = sys.argv[4]\n",
    "a5 = sys.argv[5]\n",
    "a6 = sys.argv[6]\n",
    "a7 = sys.argv[7]\n",
    "\n",
    "logging.info(f\"0:{a0}\\n1:{a1}\\n2:{a2}\\n3:{a3}\\n4:{a4}\\n5:{a5}\\n6:{a6}\\n7:{a7}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import logging\n",
    "\n",
    "log = \"logs\"\n",
    "os.makedirs(log, exist_ok=True)\n",
    "log_path = join(log,\"debug.log\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Taking data to variable is started\n",
      "ERROR:root:An error occurred: list index out of range\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'EQP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 53>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     48\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCATEGORY\u001b[39m\u001b[38;5;124m\"\u001b[39m: [CATEGORY],\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEQP\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mEQP\u001b[49m],\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTS_DT\u001b[39m\u001b[38;5;124m\"\u001b[39m: [TS_DT],\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m: [DATA_COLUMN],\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT_DT\u001b[39m\u001b[38;5;124m\"\u001b[39m: [INPUT_DT],\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT_PERSON\u001b[39m\u001b[38;5;124m\"\u001b[39m: [INPUT_PERSON],\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT_COMMENT\u001b[39m\u001b[38;5;124m\"\u001b[39m: [INPUT_COMMENT],\n\u001b[0;32m     60\u001b[0m }\n\u001b[0;32m     62\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'EQP' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "import ibm_db\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from logging.handlers import RotatingFileHandler\n",
    "from os.path import join\n",
    "\n",
    "\n",
    "database = \"AYB_APPL\"\n",
    "host = \"10.143.16.244\"\n",
    "port =\"50000\"\n",
    "protocol=\"TCPIP\"\n",
    "user=\"IOT_DATA\"\n",
    "password=\"asd23fgh\"\n",
    "log = \"logs\"\n",
    "\n",
    "\n",
    "try:\n",
    "    os.makedirs(log, exist_ok=True)\n",
    "    logging.info(\"Log Folder is created\")\n",
    "except FileExistsError:\n",
    "    logging.info(\"Failed to create Log Folder or Log Folder already exists\")\n",
    "\n",
    "\n",
    "log_path = join(log,\"debug.log\")\n",
    "log_formatter = logging.Formatter('%(asctime)s [%(levelname)s]: %(message)s')\n",
    "log_handler = RotatingFileHandler(filename=log_path, maxBytes=1048576, backupCount=10, delay=True)\n",
    "log_handler.setFormatter(log_formatter)\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)  \n",
    "logger.addHandler(log_handler)\n",
    "\n",
    "logging.info(f\"Taking data to variable is started\")\n",
    "\n",
    "try:\n",
    "    CATEGORY = sys.argv[1]\n",
    "    EQP = sys.argv[2]\n",
    "    TS_DT = sys.argv[3]\n",
    "    DATA_COLUMN = sys.argv[4]\n",
    "    INPUT_DT = sys.argv[5]\n",
    "    INPUT_PERSON = sys.argv[6]\n",
    "    INPUT_COMMENT = sys.argv[7]\n",
    "    logging.info(f\"\\n1:{CATEGORY}\\n2:{EQP}\\n3:{TS_DT}\\n4:{DATA_COLUMN}\\n5:{INPUT_DT}\\n6:{INPUT_PERSON}\\n7:{INPUT_COMMENT}\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.error(f\"An error occurred: {str(e)}\")\n",
    "\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"CATEGORY\": [CATEGORY],\n",
    "    \"EQP\": [EQP],\n",
    "    \"TS_DT\": [TS_DT],\n",
    "    \"DATA_COLUMN\": [DATA_COLUMN],\n",
    "    \"INPUT_DT\": [INPUT_DT],\n",
    "    \"INPUT_PERSON\": [INPUT_PERSON],\n",
    "    \"INPUT_COMMENT\": [INPUT_COMMENT],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "if df:\n",
    "    logging.info(\"df is created\")\n",
    "    \n",
    "def insert_into_database(df):\n",
    "    logging.info(\"Inserting into database  is started\")\n",
    "    try:\n",
    "        dsn = f\"DATABASE={database};HOSTNAME={host};PORT={port};PROTOCOL={protocol};UID={user};PWD={password}\"\n",
    "        conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "        if conn:\n",
    "            print(\"Connected to Database\")\n",
    "            logging.info(\"Connected to Database\")\n",
    "    except Exception as e:\n",
    "        print(\"Failed to Connect to Database:\", e)\n",
    "        logging.info(\"Failed to Connect to Database\")\n",
    "        logging.info(f\"Failed to Connect to Database:{e}\")\n",
    "    \n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            category = row[\"CATEGORY\"]\n",
    "            eqp = row[\"EQP\"]\n",
    "            ts_dt = row[\"TS_DT\"]\n",
    "            data_column = row[\"DATA_COLUMN\"]\n",
    "            input_dt = row[\"INPUT_DT\"]\n",
    "            input_person = row[\"INPUT_PERSON\"]\n",
    "            input_comment = row[\"INPUT_COMMENT\"]\n",
    "\n",
    "            sql = \"UPDATE IOT_DATA.THRESHOLD_ALERT SET INPUT_DT=?, INPUT_PERSON=?, INPUT_COMMENT=? WHERE CATEGORY=? AND EQP=? AND TS_DT=? AND DATA_COLUMN=?\"\n",
    "            params = (input_dt, input_person, input_comment, category, eqp, ts_dt, data_column)\n",
    "\n",
    "            stmt = ibm_db.prepare(conn, sql)\n",
    "            if ibm_db.execute(stmt, params):\n",
    "                print(\"Update successful\")\n",
    "                logging.info(f\"Updated successful\")\n",
    "            else:\n",
    "                print(\"Failed to update\")\n",
    "                logging.info(f\"Failed to update\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while updating:\", e)\n",
    "        logging.info(\"Error occurred while updating\")\n",
    "        logging.info(e)\n",
    "\n",
    "insert_into_database(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd \n",
    "\n",
    "database_1 =  \"fms01\"\n",
    "host_1 = \"10.143.64.54\"\n",
    "port_1 =  \"5432\"\n",
    "protocol_1 = \"TCPIP\"\n",
    "user_1 = \"postgres\"\n",
    "password_1 = \"fms\"\n",
    "\n",
    "conn = psycopg2.connect(database=database_1, user=user_1, password=password_1, host=host_1, port=port_1)\n",
    "\n",
    "sql_query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM mm_01 \n",
    "    WHERE state IN (2, 3);\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(sql_query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_db\n",
    "\n",
    "database_2 = \"AYB_APPL\"\n",
    "host_2 = \"10.143.16.244\"\n",
    "port_2 =\"50000\"\n",
    "protocol_2=\"TCPIP\"\n",
    "user_2=\"IOT_DATA\"\n",
    "password_2=\"asd23fgh\"\n",
    "\n",
    "\n",
    "dsn = f\"DATABASE={database_2};HOSTNAME={host_2};PORT={port_2};PROTOCOL={protocol_2};UID={user_2};PWD={password_2}\"\n",
    "conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "if conn:\n",
    "    print(\"Connected to the database\")\n",
    "else:\n",
    "    print(\"Not connected to the database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insertion_time = dt.datetime.strptime(\"2023/10/20 23:59:55\", '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "\n",
    "time = dt.datetime.strptime(\"2023/10/20 23:59:55\", '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "sql_query = '''\n",
    "    SELECT *\n",
    "    FROM table\n",
    "    WHERE state IN (2, 3) AND timestamp_column >= '{}';\n",
    "'''.format(time)\n",
    "\n",
    "df = pd.read_sql_query(sql_query, conn)\n",
    "\n",
    "data = tuple(tuple(row) for row in df.values)\n",
    "values = \",\".join(map(str, data))\n",
    "\n",
    "insert_query = f\"INSERT INTO Table_Name (Column_1, Column_2, Column_3, Column_4) VALUES {values}\"\n",
    "stmt = ibm_db.prepare(conn, insert_query)\n",
    "\n",
    "try:\n",
    "    if ibm_db.execute(stmt, values):\n",
    "        logging.info(f\"{csv} : Inserted\")\n",
    "    with open(json_path, 'w') as output_file:\n",
    "        output_file.write(json_data)\n",
    "except:\n",
    "    logging.info(f\"{csv} : is already Updated\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Column_1': [1, 2, 3],\n",
    "        'Column_2': ['A', 'B', 'C'],\n",
    "        'Column_3': [4.5, 6.7, 8.1],\n",
    "        'Column_4': ['X', 'Y', 'Z']}\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Column_1', 'Column_2', 'Column_3', 'Column_4'])\n",
    "\n",
    "columns = df.columns\n",
    "values = \",\".join([\"%s\"] * len(columns))\n",
    "data = [tuple(row) for row in df[columns].values]\n",
    "insert_query = f\"INSERT INTO Table_Name ({', '.join(columns)}) VALUES ({values})\"\n",
    "\n",
    "print(\"Sample DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nGenerated INSERT Query:\")\n",
    "print(insert_query)\n",
    "data]\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "rows= tuple(tuple(row) for row in df.values)\n",
    "string_rows = \",\".join(map(str, rows))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "rows= tuple(tuple(row) for row in df.values)\n",
    "string_rows = \",\".join(map(str, rows))\n",
    "\n",
    "print(df)\n",
    "print(df.va)\n",
    "print(string_rows)\n",
    "\n",
    "columns = ['Column_1', 'Column_2', 'Column_3', 'Column_4']\n",
    "rows = [tuple(row) for row in df[columns].values]\n",
    "values = \",\".join([\"%s\"] * len(columns))\n",
    "sql_query = f\"INSERT INTO Table_Name ({', '.join(columns)}) VALUES ({values})\"\n",
    "\n",
    "rows = [tuple(row) for row in df[columns].values]\n",
    "\n",
    "df[columns].values\n",
    "\n",
    "data = tuple(tuple(row) for row in df.values)\n",
    "values = \",\".join(map(str, data))\n",
    "\n",
    "with open(json_path) as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "config['insertion_time'] = str(df['Timestamp'].max())\n",
    "json_data = json.dumps(config, indent=2)\n",
    "\n",
    "with open(json_path, 'w') as output_file:\n",
    "    output_file.write(json_data)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "UPDATE IOT_DATA.THRESHOLD_ALERT \n",
    "SET INPUT_DT='2024/04/08 1:00:00', \n",
    "    INPUT_PERSON='Murodil', \n",
    "    INPUT_COMMENT='Test' \n",
    "WHERE CATEGORY='Particles' \n",
    "  AND EQP='MM_01' \n",
    "  AND TS_DT='2024/04/05 3:17:57' \n",
    "  AND DATA_COLUMN='0.5, 1.0, 5.0, 10.0'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import ibm_db\n",
    "\n",
    "database_2 = \"AYB_APPL\"\n",
    "host_2 = \"10.143.16.244\"\n",
    "port_2 =\"50000\"\n",
    "protocol_2=\"TCPIP\"\n",
    "user_2=\"IOT_DATA\"\n",
    "password_2=\"asd23fgh\"\n",
    "\n",
    "dsn = f\"DATABASE={database_2};HOSTNAME={host_2};PORT={port_2};PROTOCOL={protocol_2};UID={user_2};PWD={password_2}\"\n",
    "conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "if conn:\n",
    "    print(\"Connected to the database\")\n",
    "else:\n",
    "    print(\"Not connected to the database\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
