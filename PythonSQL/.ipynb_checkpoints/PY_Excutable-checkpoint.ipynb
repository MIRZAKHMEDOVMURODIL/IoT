{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495ee047-a33d-4b19-8035-7ea9ee4a5da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to the database\n",
      "Latest CSV file: C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231022.csv\n",
      "Row 1 merged successfully\n",
      "Row 2 merged successfully\n",
      "Row 3 merged successfully\n",
      "Row 4 merged successfully\n",
      "Row 5 merged successfully\n",
      "Row 6 merged successfully\n",
      "Row 7 merged successfully\n",
      "Row 8 merged successfully\n",
      "Row 9 merged successfully\n",
      "Row 10 merged successfully\n",
      "Row 11 merged successfully\n",
      "Row 12 merged successfully\n",
      "Row 13 merged successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231001.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231002.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231003.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231004.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231005.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231006.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231007.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231008.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231009.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231010.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231011.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231012.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231013.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231014.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231015.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231016.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231017.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231018.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231019.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231020.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231021.csv : Inserted successfully\n",
      "C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\\2026\\20231022.csv : Inserted successfully\n",
      "All CSV files are inserted\n",
      "Time spent: 53.136682987213135 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import ibm_db\n",
    "import logging\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "from datetime import datetime\n",
    "import datetime as dt \n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "conn = ibm_db.connect(\"DATABASE=AYB_APPL;HOSTNAME=10.143.16.244;PORT=50000;PROTOCOL=TCPIP;UID=IOT_DATA;PWD=asd23fgh;\", \"\", \"\")\n",
    "if conn:\n",
    "    print(\"Connected to the database\")\n",
    "\n",
    "\n",
    "    \n",
    "# 1) LOCATIONの最新のデータをINSERT/UPDATE\n",
    "\n",
    "\n",
    "#1.  最新フォルダの全CSVのPATHをまとめる。\n",
    "directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "file_pattern = '20*'  \n",
    "files = glob.glob(os.path.join(directory, file_pattern))\n",
    "files.sort()\n",
    "folder_path = files[-1]\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "\n",
    "\n",
    "#2. 最新のCSVファイルを探す。\n",
    "if csv_files:  \n",
    "    latest_csv_file = max(csv_files, key=os.path.getmtime)  \n",
    "    df = pd.read_csv(latest_csv_file, encoding='cp932',dtype= object)\n",
    " \n",
    "#3. CSVファイルのLocationカラムから最新の値を変数に入れる。\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    a = df['Location'].unique()\n",
    "    latest_data = pd.DataFrame()\n",
    "    df_concat = []\n",
    "    for location in a:\n",
    "        latest_location = df[df['Location'] == location].nlargest(1, 'Timestamp')\n",
    "        df_concat.append(latest_location)\n",
    "    latest_data = pd.concat(df_concat, ignore_index=True)\n",
    "    print(\"Latest CSV file:\", latest_csv_file)\n",
    "    \n",
    "else:\n",
    "    print(\"No CSV files found in the folder.\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "# 4. データがあればUPDATE, データがなければINSERTする。\n",
    "merge_query = \"\"\"\n",
    "MERGE INTO LIQUID_PARTICLE_LAST AS target\n",
    "USING (SELECT ? AS LOCATION, ? AS TS_DT, ? AS VALUE_1_0, ? AS VALUE_3_0, ? AS VALUE_5_0, ? AS VALUE_10_0, ? AS VALUE_15_0, ? AS VALUE_20_0, ? AS VALUE_25_0, ? AS VALUE_50_0 FROM SYSIBM.SYSDUMMY1) AS source\n",
    "ON target.LOCATION = source.LOCATION\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET target.TS_DT = source.TS_DT, \n",
    "               target.VALUE_1_0 = source.VALUE_1_0, \n",
    "               target.VALUE_3_0 = source.VALUE_3_0, \n",
    "               target.VALUE_5_0 = source.VALUE_5_0, \n",
    "               target.VALUE_10_0 = source.VALUE_10_0, \n",
    "               target.VALUE_15_0 = source.VALUE_15_0, \n",
    "               target.VALUE_20_0 = source.VALUE_20_0, \n",
    "               target.VALUE_25_0 = source.VALUE_25_0, \n",
    "               target.VALUE_50_0 = source.VALUE_50_0\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT (LOCATION, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0)\n",
    "    VALUES (source.LOCATION, source.TS_DT, source.VALUE_1_0, source.VALUE_3_0, source.VALUE_5_0, source.VALUE_10_0, source.VALUE_15_0, source.VALUE_20_0, source.VALUE_25_0, source.VALUE_50_0);\n",
    "\"\"\"\n",
    "\n",
    "stmt = ibm_db.prepare(conn, merge_query)\n",
    "\n",
    "for index, row in latest_data.iterrows():\n",
    "    location = row['Location']\n",
    "    timestamp = row['Timestamp']\n",
    "    c1 = row['1.0μｍ']\n",
    "    c3 = row['3.0μｍ']\n",
    "    c5 = row['5.0μｍ']\n",
    "    c10 = row['10.0μｍ']\n",
    "    c15 = row['15.0μｍ']\n",
    "    c20 = row['20.0μｍ']\n",
    "    c25 = row['25.0μｍ']\n",
    "    c50 = row['50.0μｍ']\n",
    "    \n",
    "    if ibm_db.execute(stmt, (location, timestamp, c1, c3, c5, c10, c15, c20, c25, c50)):\n",
    "        print(f\"Row {index + 1} merged successfully\")\n",
    "    else:\n",
    "        print(f\"Error merging row {index + 1}: {ibm_db.stmt_errormsg()}\")\n",
    "\n",
    "\n",
    "        \n",
    "#############################################################################################################\n",
    "        \n",
    "# 2) JSON記録に記載された日より、以降のデータをCSVファイルごとにINSERTする\n",
    "\n",
    "        \n",
    "#　1.JSONの記録からデータベースに最後INSERTされた時刻を取得する\n",
    "\n",
    "with open('insertion_time.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    inserted_time = dt.datetime.strptime(data['insertion_time'], '%Y-%m-%d %H:%M:%S')\n",
    "    inserted_day = inserted_time.strftime('%Y%m%d')\n",
    "    time_to_compare = data['insertion_time']\n",
    "\n",
    "    \n",
    "\n",
    "#  2.最新のフォルダから,全CSVのPATHをまとめる\n",
    "\n",
    "directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "file_pattern = '20*'  \n",
    "files = glob.glob(os.path.join(directory, file_pattern))\n",
    "files.sort()\n",
    "folder_path = files[-1]\n",
    "csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 　3.JSON記録に記載された日と、それより以降のCSV1をまとめる  \n",
    "selected_csv_files=[]\n",
    "selected_csv_files = [file for file in csv_files if int(file[-12:-4]) >= int(inserted_day)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   4.JSON記録に記載された日より以降のCSV1を１つずつINSERTする  \n",
    "if selected_csv_files:\n",
    "    \n",
    "    for i in selected_csv_files:\n",
    "        df = pd.read_csv(fr\"{i}\", encoding='cp932', dtype= object)\n",
    "        df['Timestamp'] = df['Timestamp'].str.replace('/', '-', regex=False)\n",
    "        \n",
    "        a = df[df['Timestamp'] >  time_to_compare]\n",
    "        data = tuple(tuple(row) for row in a.values )\n",
    "           \n",
    "        b = \"\"\n",
    "        for row in data:\n",
    "            b += str(row) +\",\"\n",
    "        b = b[:-1]\n",
    "        \n",
    "        insert_query = f\"INSERT INTO LIQUID_PARTICLE_TEST (Location, TS_DT, VALUE_1_0, VALUE_3_0, VALUE_5_0, VALUE_10_0, VALUE_15_0, VALUE_20_0, VALUE_25_0, VALUE_50_0) VALUES {b}\"\n",
    "        stmt = ibm_db.prepare(conn, insert_query)\n",
    "        \n",
    "        try:\n",
    "            if ibm_db.execute(stmt, b):\n",
    "                print(f\"{i} : Inserted successfully\")     \n",
    "        except:\n",
    "            print(f\"({i}) is already updated\")\n",
    "                \n",
    "        \n",
    "#   5.時間を JSON ファイルに保存する   \n",
    "    \n",
    "        insertion_time = a['Timestamp'].max()\n",
    "        json_data = {'insertion_time': insertion_time}\n",
    "        with open('insertion_time.json', 'w') as json_file:\n",
    "            json.dump(json_data, json_file, indent=4)\n",
    "    print('All CSV files are inserted')\n",
    "elif not selected_csv_files:\n",
    "    print(\"Database is already updated\")\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Time spent: {elapsed_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff83101-84f8-48a2-babe-bffc750c755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74237f-1662-4c7c-88d1-6614b49897b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(json_file_path):\n",
    "#     with open(json_file_path, 'r') as json_file:\n",
    "#         data = json.load(json_file)\n",
    "#         inserted_time = dt.datetime.strptime(data['insertion_time'], '%Y-%m-%d %H:%M:%S')\n",
    "#         inserted_day = inserted_time.strftime('%Y%m%d')\n",
    "#         time_to_compare = data['insertion_time']\n",
    "#         print(f\"Last Insertion time: {time_to_compare}\")\n",
    "#     directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "#     file_pattern = '20*'  \n",
    "#     files = glob.glob(os.path.join(directory, file_pattern))\n",
    "#     files.sort()\n",
    "#     folder_path = files[-1]\n",
    "#     csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n",
    "#     selected_csv_files=[]\n",
    "#     selected_csv_files = [file for file in csv_files if int(file[-12:-4]) >= int(inserted_day)]\n",
    "#     selected_csv_files\n",
    "# else:\n",
    "#     print(\"JSON file does not exist. All CSV files below are going to be inserted into the database.\")\n",
    "#     logging.info(\"JSON file does not exist. All CSV files below are going to be inserted into the database.\")\n",
    "#     directory =  r\"C:\\Users\\00220401626\\Desktop\\FMS\\CsvData\"\n",
    "#     file_pattern = '20*'  \n",
    "#     files = glob.glob(os.path.join(directory, file_pattern))\n",
    "#     files.sort()\n",
    "#     folder_path = files[-1]\n",
    "#     selected_csv_files = glob.glob(os.path.join(folder_path, '*.csv'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
